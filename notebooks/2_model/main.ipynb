{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71ccff01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training_folder': '../../scenarios/clermont', 'params': {'general': {'step_size': '0.001', 'use_road_network': True, 'coef_day_to_year': '300', 'clustering_radius': '500'}}}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "\n",
    "general = {'step_size': '0.001', 'use_road_network': True, 'coef_day_to_year': '300', 'clustering_radius': '500'}\n",
    "\n",
    "params = {\n",
    "    'general': general,\n",
    "    }\n",
    "\n",
    "default = {'training_folder': '../../scenarios/clermont', 'params':params} # Default execution parameters\n",
    "manual, argv = (True, default) if 'ipykernel' in sys.argv[0] else (False, dict(default, **json.loads(sys.argv[1])))\n",
    "print(argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99b5db61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numba threads 20\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 50)\n",
    "sys.path.insert(0, r'../../../quetzal') # Add path to quetzal\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point, LineString\n",
    "from typing import Literal\n",
    "import numba as nb\n",
    "from collections import defaultdict\n",
    "from sklearn.cluster import DBSCAN\n",
    "import shapely\n",
    "#num_cores = 1\n",
    "print('numba threads',nb.config.NUMBA_NUM_THREADS)\n",
    "\n",
    "on_lambda = bool(os.environ.get('AWS_EXECUTION_ENV'))\n",
    "io_engine = 'pyogrio' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "772a187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, r'../../') # Add path\n",
    "from utils import get_epsg, population_to_mesh, get_acf_distances, get_routing_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c740a4",
   "metadata": {},
   "source": [
    "# Folders stucture and params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbbcb7a",
   "metadata": {},
   "source": [
    "Everything is on S3 (nothing on ECR) so no direct input folder. just scenarios/{scen}/inputs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ade8441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../scenarios/clermont'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argv['training_folder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d16ff565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'general': {'step_size': '0.001',\n",
       "  'use_road_network': True,\n",
       "  'coef_day_to_year': '300',\n",
       "  'clustering_radius': '500'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argv['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e405b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = argv['training_folder']\n",
    "input_folder = os.path.join(base_folder,'inputs/')\n",
    "pt_folder  = os.path.join(input_folder,'pt/')\n",
    "road_folder = os.path.join(input_folder,'road/') ## réseau ferré\n",
    "od_folder =  os.path.join(input_folder,'od/')\n",
    "\n",
    "output_folder = os.path.join(base_folder,'outputs/')\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "model_folder = os.path.join(input_folder, 'model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81b11c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read general params\n",
    "step_size_min = 0.0005\n",
    "step_size = max(float(argv['params']['general'].get('step_size')), step_size_min)\n",
    "use_road_network = argv['params']['general'].get('use_road_network') ## param use r_ntw\n",
    "coef_day_to_year = float(argv['params']['general'].get('coef_day_to_year'))\n",
    "clustering_radius = float(argv['params']['general'].get('clustering_radius'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d656677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default pt_links params in case not filled by the user\n",
    "default_catchment_radius = 500      # meters\n",
    "default_capex = 0.3                 # €/veh.km\n",
    "default_capacity = 60               # vehicle capacity in PAX\n",
    "default_service_hours = 12          # nb d'heures par jour de fonctionnement\n",
    "#TODO: voir si on peut ajouter les champs défaut dans les liens ==> suppr. ==> adapter script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd032bd",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bacf9ca",
   "metadata": {},
   "source": [
    "PT links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b5ada42",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pt_folder + 'links.geojson') as f:\n",
    "    links_ = json.load(f)\n",
    "\n",
    "columns = set()\n",
    "for feature in links_['features']:\n",
    "    for key in feature['properties'].keys():\n",
    "        columns.add(key)\n",
    "\n",
    "links = pd.DataFrame(links_['features'])\n",
    "for col in columns:\n",
    "    links[col] = links.apply(lambda x: x['properties'].get(col, None), 1)\n",
    "links['geometry'] = links['geometry'].apply(lambda x: LineString(x['coordinates']))\n",
    "links.drop(columns=['type', 'properties'], inplace=True)\n",
    "\n",
    "links = links.set_index('index')\n",
    "links = gpd.GeoDataFrame(links, geometry='geometry', crs='EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a674100",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = gpd.read_file(pt_folder + 'nodes.geojson', engine=io_engine)\n",
    "nodes = nodes.set_index('index')\n",
    "nodes = nodes[~pd.isna(nodes.geometry)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21d54c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'capacity' not in links.columns:\n",
    "    links['capacity'] = default_capacity\n",
    "else:\n",
    "    links['capacity'] = links['capacity'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "921a0d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'capex' not in links.columns:\n",
    "    links['capex'] = default_capex\n",
    "else:\n",
    "    links['capex'] = links['capex'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "daa5b7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "catchment_radii = [x for x in links.columns if 'catchment_radius' in x]\n",
    "catchment_radii_provided = (len(catchment_radii) > 0)\n",
    "if catchment_radii_provided:\n",
    "    for x in catchment_radii:\n",
    "        M = links[x].max()\n",
    "        assert links[x].equals(links[x].fillna(M)), '!! Catchemnt radius values missing in column {} !!'.format(x)\n",
    "        links[x] = links[x].fillna(M)\n",
    "        links[x] = links[x].astype(float)\n",
    "else:\n",
    "    links['catchment_radius'] = default_catchment_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "642dc9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_service_hours = 12\n",
    "if 'nb_service_hours' not in links.columns:\n",
    "    links['nb_service_hours'] = default_service_hours\n",
    "else:\n",
    "    links['nb_service_hours'] = links['nb_service_hours'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47cc208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'departures' not in links.columns:\n",
    "    links['departures'] = None\n",
    "if 'arrivals' not in links.columns:\n",
    "    links['arrivals'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331a0486",
   "metadata": {},
   "source": [
    "Input data zoning file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d6324e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mlaune\\AppData\\Local\\Temp\\ipykernel_9004\\550055817.py:2: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  centroid = [*LineString(nodes.centroid.values).centroid.coords][0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32631"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find meters CRS\n",
    "centroid = [*LineString(nodes.centroid.values).centroid.coords][0]\n",
    "crs = get_epsg(centroid[1],centroid[0])\n",
    "crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99e4e06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zonage_file = os.path.join(input_folder, 'zonage.geojson')\n",
    "zonage_file_provided = os.path.isfile(zonage_file)\n",
    "if zonage_file_provided :\n",
    "    zonage = gpd.read_file(input_folder + 'zonage.geojson', engine=io_engine).to_crs(epsg='4326')\n",
    "    zonage['area (km2)'] = zonage.to_crs(crs).area / 10**6\n",
    "else:\n",
    "    print('No zonage file in the input folder...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ad58e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "densities = [x for x in zonage.columns if 'density' in x]\n",
    "assert len(densities) > 0, 'Please provide densities as input data in the zoning file'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ece865d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "zonage.to_crs(epsg=4326).to_file(output_folder + 'zoning.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36a141e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_ph_columns = ('headway_ph' in links.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69419eeb",
   "metadata": {},
   "source": [
    "Road network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac965c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "road network ? True\n"
     ]
    }
   ],
   "source": [
    "## road network here\n",
    "rnodes_file = os.path.join(road_folder, 'road_nodes.geojson')\n",
    "rnodes_file_provided = os.path.isfile(rnodes_file)\n",
    "if rnodes_file_provided:\n",
    "    rnodes = gpd.read_file(os.path.join(road_folder, 'road_nodes.geojson'), engine=io_engine)\n",
    "    rnodes = rnodes.set_index('index').to_crs(epsg='4326')\n",
    "    rlinks = gpd.read_file(os.path.join(road_folder, 'road_links.geojson'), engine=io_engine)\n",
    "    rlinks = rlinks.set_index('index').to_crs(epsg='4326')\n",
    "print('road network ?',rnodes_file_provided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6071cbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "od ? False\n"
     ]
    }
   ],
   "source": [
    "od_file = os.path.join(od_folder, 'od.geojson')\n",
    "od_file_provided = os.path.isfile(od_file)\n",
    "if od_file_provided:\n",
    "    od_test = gpd.read_file(od_file, engine=io_engine)\n",
    "    if 'name' not in od_test.columns:\n",
    "        od_test['name'] = od_test['index']\n",
    "    od_test['name'] = od_test['name'].fillna(od_test['index'].astype(str))\n",
    "print('od ?',od_file_provided)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0687074a",
   "metadata": {},
   "source": [
    "# Init result dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cf77ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_route_id = pd.DataFrame(index=links['route_id'].unique())\n",
    "df_route_id.index.name = 'route_id'\n",
    "df_route_id = df_route_id.reset_index()\n",
    "if display_ph_columns:   \n",
    "    df_route_id = df_route_id.merge(links[['route_id', 'route_type', 'capacity', 'headway', 'headway_ph', 'headway_oph', 'nb_peak_hours']], on='route_id', how='left')\n",
    "else:\n",
    "    df_route_id = df_route_id.merge(links[['route_id', 'route_type', 'capacity', 'headway']], on='route_id', how='left')\n",
    "df_route_id = df_route_id.rename(columns={'capacity': 'veh_capacity (PAX)'})\n",
    "df_route_id = df_route_id.drop_duplicates()\n",
    "df_route_id = df_route_id.set_index('route_id')\n",
    "\n",
    "df_trip_id = pd.DataFrame(index=links['trip_id'].unique())\n",
    "df_trip_id.index.name = 'trip_id'\n",
    "df_trip_id = df_trip_id.reset_index()\n",
    "if display_ph_columns:   \n",
    "    df_trip_id = df_trip_id.merge(links[['trip_id', 'route_id', 'route_type', 'capacity', 'headway', 'headway_ph', 'headway_oph', 'nb_peak_hours']], on='trip_id', how='left')\n",
    "else:\n",
    "    df_trip_id = df_trip_id.merge(links[['trip_id', 'route_id', 'route_type', 'capacity', 'headway']], on='trip_id', how='left')\n",
    "df_trip_id = df_trip_id.rename(columns={'capacity': 'veh_capacity (PAX)'})\n",
    "df_trip_id = df_trip_id.drop_duplicates()\n",
    "df_trip_id = df_trip_id.set_index('trip_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbac81bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_route_type = pd.DataFrame(index=links['route_type'].unique())\n",
    "df_route_type.index.name='route_type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5cc4bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure headways are consistent : one single headway for both way and return\n",
    "# Otherwise can't calculate KPIs later\n",
    "\n",
    "df_route_id = df_route_id[~df_route_id.index.duplicated(keep='first')]\n",
    "route_headway = dict(zip(df_route_id.index, df_route_id['headway']))\n",
    "links.headway = links.route_id.map(route_headway)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46210dac",
   "metadata": {},
   "source": [
    "# Geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e17d1c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "geoms_trip_id = links.groupby('trip_id')['geometry'].agg(shapely.unary_union).to_dict()\n",
    "df_trip_id['geometry'] = geoms_trip_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff5541d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "geoms_route_id = links.copy()\n",
    "geoms_route_id['trip_number'] = geoms_route_id['trip_id'].apply(lambda x: x[-1])\n",
    "geoms_route_id = geoms_route_id.loc[geoms_route_id['trip_number'] =='0']\n",
    "geoms_route_id = geoms_route_id.groupby('route_id')['geometry'].agg(shapely.unary_union).to_dict()\n",
    "df_route_id['geometry'] = geoms_route_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8fb983",
   "metadata": {},
   "source": [
    "# Catchment calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d54b3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_catchment_by_mode(col='route_id', pop_col='population', node_dist=None):\n",
    "    #get all nodes with col filter\n",
    "    link = links.groupby(col)[['a','b','route_type', 'catchment_radius']].agg({'a':set,'b':set,'route_type':'first', 'catchment_radius': 'first'})\n",
    "    link['node'] = link.apply(lambda row: row['a'].union(row['b']), axis=1)\n",
    "    link = link.drop(columns=['a','b'])\n",
    "\n",
    "    col_exist = col == 'route_type' # cannot explode if index == route_type (a column)\n",
    "    link = link.explode('node').reset_index(drop=col_exist)\n",
    "    link = node_dist.merge(link, left_on='node_index', right_on='node')\n",
    "    #filter by distance\n",
    "    link = link[link['distances'] <= link['catchment_radius']]\n",
    "    #drop duplicated mesh nodes (we count only one time)\n",
    "    link = link.drop_duplicates(subset=['mesh_index',col],keep='first')\n",
    "\n",
    "    return link.groupby(col)[pop_col].sum().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b150d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_catchment_by_access(col='route_id', pop_col='population', catchment_col='catchment_radius', node_dist=None):\n",
    "    #get all nodes with col filter\n",
    "    link = links.groupby(col)[['a','b','route_type', catchment_col]].agg({'a':set,'b':set,'route_type':'first', catchment_col:'first'})\n",
    "    link['node'] = link.apply(lambda row: row['a'].union(row['b']), axis=1)\n",
    "    link = link.drop(columns=['a','b'])\n",
    "\n",
    "    col_exist = col == 'route_type' # cannot explode if index == route_type (a column)\n",
    "    link = link.explode('node').reset_index(drop=col_exist)\n",
    "    link = node_dist.merge(link, left_on='node_index', right_on='node')\n",
    "    #filter by distance\n",
    "    # link[catchment_col] = link[catchment_col].astype(float)\n",
    "    link = link[link['distances'] <= link[catchment_col]]\n",
    "    #drop duplicated mesh nodes (we count only one time)\n",
    "    link = link.drop_duplicates(subset=['mesh_index',col],keep='first')\n",
    "\n",
    "    return link.groupby(col)[pop_col].sum().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c438144c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "population\n",
      "using road_nodes\n",
      "0 nodes in multiple zones. will be match to a single zone.\n",
      "13 unfounded zones\n",
      "using road_nodes\n"
     ]
    }
   ],
   "source": [
    "meshes = {}\n",
    "node_dists = {}\n",
    "\n",
    "## road network here\n",
    "for density in densities:\n",
    "    if density == 'density' and 'population_density' not in densities:\n",
    "        tag = 'population'\n",
    "    elif density == 'density':\n",
    "        tag = 'x'\n",
    "    else:\n",
    "        tag = density.split('_density')[0]\n",
    "\n",
    "    print(tag)\n",
    "\n",
    "    zonage[tag] = zonage[density] * zonage['area (km2)']\n",
    "\n",
    "    if rnodes_file_provided and use_road_network:\n",
    "        # use rnodes as mesh_pop.\n",
    "        print('using road_nodes') ## road network here\n",
    "        mesh = population_to_mesh(zonage, mesh=rnodes, step=step_size, col=tag, fill_missing='closest')\n",
    "    else:\n",
    "        # create a mesh\n",
    "        mesh = population_to_mesh(zonage, mesh=None, step=step_size, col=tag, fill_missing='centroid')\n",
    "\n",
    "    #mesh.to_file(output_folder + 'population_mesh.geojson',driver='GeoJSON',engine=io_engine)\n",
    "    if catchment_radii_provided:\n",
    "        max_dist = (max([links[catchment_radius].max() for catchment_radius in catchment_radii]))\n",
    "    else:\n",
    "        max_dist = default_catchment_radius\n",
    "\n",
    "    meshes[tag] = mesh.copy()\n",
    "\n",
    "    # road network here, what to use if not road network?\n",
    "    if rnodes_file_provided: \n",
    "        print('using road_nodes')\n",
    "        node_dist = get_routing_distances(nodes, rnodes, rlinks, mesh, tag, 'length', max_dist)\n",
    "    else:\n",
    "        node_dist = get_acf_distances(nodes, mesh, tag, crs, max_dist)\n",
    "\n",
    "    node_dists[tag] = node_dist.copy()\n",
    "    \n",
    "    if catchment_radii_provided:\n",
    "        for catchment_radius in catchment_radii:\n",
    "            suf = catchment_radius.split('catchment_radius_')[1]\n",
    "\n",
    "            res_trip = get_catchment_by_access('trip_id', tag, catchment_radius, node_dist)\n",
    "            res_route = get_catchment_by_access('route_id', tag, catchment_radius, node_dist)\n",
    "            res_mode = get_catchment_by_access('route_type', tag, catchment_radius, node_dist)\n",
    "\n",
    "            if suf == '':\n",
    "                df_trip_id['catchment {}'.format(tag)] = res_trip\n",
    "                df_trip_id['catchment {}'.format(tag)] = df_trip_id['catchment {}'.format(tag)].fillna(0) \n",
    "\n",
    "                df_route_id['catchment {}'.format(tag)] = res_route\n",
    "                df_route_id['catchment {}'.format(tag)] = df_route_id['catchment {}'.format(tag)].fillna(0) \n",
    "\n",
    "                df_route_type['catchment {}'.format(tag)] = res_mode\n",
    "                df_route_type['catchment {}'.format(tag)] = df_route_type['catchment {}'.format(tag)].fillna(0) \n",
    "\n",
    "            else:\n",
    "                df_trip_id['catchment {} {}'.format(tag, suf)] = res_trip\n",
    "                df_trip_id['catchment {} {}'.format(tag, suf)] = df_trip_id['catchment {} {}'.format(tag, suf)].fillna(0) \n",
    "\n",
    "                df_route_id['catchment {} {}'.format(tag, suf)] = res_route\n",
    "                df_route_id['catchment {} {}'.format(tag, suf)] = df_route_id['catchment {} {}'.format(tag, suf)].fillna(0) \n",
    "\n",
    "                df_route_type['catchment {} {}'.format(tag, suf)] = res_mode\n",
    "                df_route_type['catchment {} {}'.format(tag, suf)] = df_route_type['catchment {} {}'.format(tag, suf)].fillna(0) \n",
    "\n",
    "    else:\n",
    "        res_trip = get_catchment_by_mode('trip_id', tag, node_dist)\n",
    "        res_route = get_catchment_by_mode('route_id', tag, node_dist)\n",
    "        res_mode = get_catchment_by_mode('route_type', tag, node_dist)\n",
    "\n",
    "        df_trip_id['catchment {}'.format(tag)] = res_trip\n",
    "        df_trip_id['catchment {}'.format(tag)] = df_trip_id['catchment {}'.format(tag)].fillna(0) \n",
    "\n",
    "        df_route_id['catchment {}'.format(tag)] = res_route\n",
    "        df_route_id['catchment {}'.format(tag)] = df_route_id['catchment {}'.format(tag)].fillna(0) \n",
    "\n",
    "        df_route_type['catchment {}'.format(tag)] = res_mode\n",
    "        df_route_type['catchment {}'.format(tag)] = df_route_type['catchment {}'.format(tag)].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5d12fd",
   "metadata": {},
   "source": [
    "# Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c661a29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'departures' in links.columns:\n",
    "    links['link_has_timetable'] = links['departures'].apply(lambda x: 0 if x is None else 1)\n",
    "    lines_with_timetable = links.groupby('route_id')['link_has_timetable'].min()\n",
    "    links['line_has_timetable'] = links['route_id'].map(lines_with_timetable)\n",
    "    links.drop(columns='link_has_timetable', inplace=True)\n",
    "else:\n",
    "    links['line_has_timetable'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f15f321",
   "metadata": {},
   "outputs": [],
   "source": [
    "default = {'headway_ph': links['headway'].max(),\n",
    "           'headway_oph': links['headway'].max(),\n",
    "           'nb_service_hours': 14,\n",
    "           'nb_peak_hours': 14}\n",
    "\n",
    "dic_headway = links.groupby('route_id')['headway'].min()\n",
    "\n",
    "for col in ['headway_ph', 'headway_oph']:\n",
    "    if col not in links.columns:\n",
    "        links[col] = default[col]\n",
    "    else: \n",
    "        dic_col = links.groupby('route_id')[col].min()\n",
    "        links[col] = links['route_id'].map(dic_col)\n",
    "        links.loc[links[col].isna(), col] = links.loc[links[col].isna(), 'route_id'].map(dic_headway)\n",
    "        links[col] = links[col].astype(int)\n",
    "\n",
    "for col in ['nb_service_hours', 'nb_peak_hours']:\n",
    "    if col not in links.columns:\n",
    "        links[col] = default[col]\n",
    "    else:\n",
    "        links[col] = links[col]\n",
    "        dic_col = links.groupby('route_id')[col].max()\n",
    "        links[col] = links['route_id'].map(dic_col).fillna(default[col])\n",
    "        links[col] = links[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f8db3069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def time_seconds(time_str):\n",
    "    time_obj = datetime.strptime(time_str, '%H:%M:%S')\n",
    "    return time_obj.hour * 3600 + time_obj.minute * 60 + time_obj.second\n",
    "\n",
    "def retrieve_avg_headway(departures):\n",
    "    deps_seconds = [time_seconds(t) for t in departures]\n",
    "    if len(deps_seconds) >= 1:\n",
    "        gaps = [deps_seconds[i] - deps_seconds[i-1] for i in range(1, len(deps_seconds))]\n",
    "        return int(np.average(gaps))\n",
    "    return None\n",
    "\n",
    "def retrieve_oph_headway(departures):\n",
    "    deps_seconds = [time_seconds(t) for t in departures]\n",
    "    if len(deps_seconds) >= 1:\n",
    "        gaps = [deps_seconds[i] - deps_seconds[i-1] for i in range(1, len(deps_seconds))]\n",
    "        return max(gaps)\n",
    "    return None\n",
    "\n",
    "def retrieve_ph_headway(departures):\n",
    "    deps_seconds = [time_seconds(t) for t in departures]\n",
    "    if len(deps_seconds) >= 1:\n",
    "        gaps = [deps_seconds[i] - deps_seconds[i-1] for i in range(1, len(deps_seconds))]\n",
    "        return min(gaps)\n",
    "    return None\n",
    "\n",
    "def retrieve_service_hours(departures):\n",
    "    deps_seconds = [time_seconds(t) for t in departures]\n",
    "    if len(deps_seconds) >= 1:\n",
    "        return (deps_seconds[-1] - deps_seconds[0])/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81e40ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "links.loc[links['line_has_timetable'] == 1, 'frequency_per_day'] = links.loc[links['line_has_timetable'] == 1].apply(lambda x: len(x['departures']), 1)\n",
    "links.loc[links['line_has_timetable'] == 0, 'frequency_per_day'] = links.loc[links['line_has_timetable'] == 0].apply(lambda x: np.ceil(3600*(x['nb_peak_hours']/x['headway_ph'] + (x['nb_service_hours'] - x['nb_peak_hours'])/x['headway_oph'])), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba168d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "links.loc[links['line_has_timetable']==1, 'headway'] = links.loc[links['line_has_timetable']==1, 'departures'].apply(retrieve_avg_headway)\n",
    "links.loc[links['line_has_timetable']==1, 'headway_ph'] = links.loc[links['line_has_timetable']==1, 'departures'].apply(retrieve_ph_headway)\n",
    "links.loc[links['line_has_timetable']==1, 'headway_oph'] = links.loc[links['line_has_timetable']==1, 'departures'].apply(retrieve_oph_headway)\n",
    "links.loc[links['line_has_timetable']==1, 'nb_service_hours'] = links.loc[links['line_has_timetable']==1, 'departures'].apply(retrieve_service_hours)\n",
    "links.loc[links['line_has_timetable']==1, 'nb_peak_hours'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e84f1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "links['frequency (veh/hour)'] = 1/links['headway']*3600\n",
    "links['frequency ph (veh/hour)'] = 1/links['headway_ph']*3600\n",
    "links['frequency oph (veh/hour)'] = 1/links['headway_oph']*3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b7a34049",
   "metadata": {},
   "outputs": [],
   "source": [
    "links['headway'] = links.apply(lambda x: x['headway'] if (x['headway_ph'] == x['headway_oph']) else None, 1)\n",
    "links['frequency (veh/hour)'] = links.apply(lambda x: x['frequency (veh/hour)'] if (x['frequency ph (veh/hour)'] == x['frequency oph (veh/hour)']) else None, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3d8badd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_hour = (links.groupby('route_id')['frequency (veh/hour)'].agg('mean')).to_dict()\n",
    "res_day = (links.groupby('route_id')['frequency_per_day'].agg('mean')).to_dict()\n",
    "\n",
    "df_route_id['frequency (veh/day)'] = res_day\n",
    "df_route_id['frequency (veh/hour)'] = res_hour\n",
    "\n",
    "if display_ph_columns:\n",
    "    res_ph = (links.loc[links['frequency ph (veh/hour)'] != links['frequency oph (veh/hour)']].groupby('route_id')['frequency ph (veh/hour)'].agg('mean')).to_dict()\n",
    "    res_oph = (links.loc[links['frequency ph (veh/hour)'] != links['frequency oph (veh/hour)']].groupby('route_id')['frequency oph (veh/hour)'].agg('mean')).to_dict()\n",
    "\n",
    "    df_route_id['frequency ph (veh/hour)'] = res_ph\n",
    "    df_route_id['frequency oph (veh/hour)'] = res_oph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "09422553",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_hour = (links.groupby('trip_id')['frequency (veh/hour)'].agg('mean')).to_dict()\n",
    "res_day = (links.groupby('trip_id')['frequency_per_day'].agg('mean')).to_dict()\n",
    "\n",
    "df_trip_id['frequency (veh/day)'] = res_day\n",
    "df_trip_id['frequency (veh/hour)'] = res_hour\n",
    "\n",
    "if display_ph_columns:\n",
    "    res_ph = (links.loc[links['frequency ph (veh/hour)'] != links['frequency oph (veh/hour)']].groupby('trip_id')['frequency ph (veh/hour)'].agg('mean')).to_dict()\n",
    "    res_oph = (links.loc[links['frequency ph (veh/hour)'] != links['frequency oph (veh/hour)']].groupby('trip_id')['frequency oph (veh/hour)'].agg('mean')).to_dict()\n",
    "\n",
    "    df_trip_id['frequency ph (veh/hour)'] = res_ph\n",
    "    df_trip_id['frequency oph (veh/hour)'] = res_oph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "44a662c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_hour = (links.groupby('route_type')['frequency (veh/hour)'].agg('mean')).to_dict()\n",
    "res_day = (links.groupby('route_type')['frequency_per_day'].agg('mean')).to_dict()\n",
    "\n",
    "df_route_type['frequency (veh/day)'] = res_day\n",
    "df_route_type['frequency (veh/hour)'] = res_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a16eb3",
   "metadata": {},
   "source": [
    "# Line Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3273ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length(col='route_id', length_col='length'):\n",
    "    link = links.groupby([col,'trip_id'])[[length_col]].agg(np.nansum)\n",
    "    if col == 'route_type':\n",
    "        return link.reset_index().groupby(col)[length_col].agg(np.nansum).to_dict()\n",
    "    else:\n",
    "        return link.reset_index().groupby(col)[length_col].agg(np.nanmean).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bfa2e75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparation. if length is NaN, or if shape dist travel exist.\n",
    "\n",
    "length_col = None\n",
    "if 'length' in links.columns and length_col == None:\n",
    "    if len(links[links['length'].isnull()])==0:\n",
    "        length_col = 'length'\n",
    "        \n",
    "if 'shape_dist_traveled' in links.columns and length_col == None:\n",
    "    if len(links[links['shape_dist_traveled'].isnull()])==0:\n",
    "        length_col = 'shape_dist_traveled'\n",
    "\n",
    "if length_col == None:\n",
    "    print('create length from geometry')\n",
    "    links['length'] = links.to_crs(crs).length\n",
    "    length_col = 'length'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "31db0758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112065.5\n"
     ]
    }
   ],
   "source": [
    "res = get_length('route_id',length_col)\n",
    "\n",
    "df_route_id['length (m)'] = res\n",
    "print(sum([item for key,item in res.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "39826011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224131\n"
     ]
    }
   ],
   "source": [
    "res = get_length('route_type',length_col)\n",
    "\n",
    "df_route_type['length (m)'] = res\n",
    "print(sum([item for key,item in res.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638013ee",
   "metadata": {},
   "source": [
    "# Number of station per line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6bf1bd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# o-->o-->o-->o and  o<--o<--o<--o\n",
    "# est-ce que j'ai 8 ou 4 stations ?\n",
    "# j'ai 4 stations par trip et 4 stations par route (si c'est les memes).\n",
    "# comment savoir si cest les mêmes : clustering?\n",
    "# pour l'instant on prend tous les noeuds unique par route_id ou route_type (col='route_id', route_id)\n",
    "def get_num_station(col='route_id'):\n",
    "    link = links.groupby(col)[['a','b']].agg({'a':set,'b':set})\n",
    "    link['node_len'] = link.apply(lambda row: len(row['a'].union(row['b'])), axis=1)\n",
    "    return link['node_len'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "53a9fb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!! Duplicates in node names !!\n"
     ]
    }
   ],
   "source": [
    "nodes['nindex'] = nodes.reset_index().index\n",
    "nodes['stop_name'] = nodes.apply(lambda x: x['nindex'] if (pd.isna(x['stop_name']) or x['stop_name'] is None) else x['stop_name'], 1)\n",
    "nodes.drop(columns='nindex', inplace=True)\n",
    "\n",
    "links['a_name'] = links['a'].map(nodes['stop_name'].to_dict())\n",
    "links['b_name'] = links['b'].map(nodes['stop_name'].to_dict())\n",
    "\n",
    "if len(nodes['stop_name'].values.tolist()) > len(nodes['stop_name'].unique()):\n",
    "    print('!! Duplicates in node names !!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0eebf302",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_nb_trips = links[['route_id', 'trip_id']].drop_duplicates().groupby('route_id')['trip_id'].count().to_dict()\n",
    "df_route_id['type'] = df_route_id.index.map(dict_nb_trips)\n",
    "df_route_id['type'] = df_route_id['type'].apply(lambda x: 'circular' if x == 1 else 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2165039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_sequence(route_id):\n",
    "    links_route = links.loc[links.route_id == route_id]\n",
    "    if df_route_id.loc[route_id]['type'] == 'linear':\n",
    "        trip_id = route_id + '_0'\n",
    "    links_route = links_route.loc[links_route.trip_id == trip_id]\n",
    "    links_route = links_route.sort_values(by='link_sequence')\n",
    "    nodes_seq = []\n",
    "    for i in range(len(links_route)):\n",
    "        nodes_seq += [links_route.iloc[i]['a']]\n",
    "    nodes_seq += [links_route.iloc[-1]['b']]\n",
    "    return nodes_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f19ccc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_stops = dict(zip(nodes.index, nodes['stop_name']))\n",
    "\n",
    "def get_stops_sequence(route_id):\n",
    "    nodes_seq = get_node_sequence(route_id)\n",
    "    stops_seq = []\n",
    "    for node in nodes_seq:\n",
    "        stops_seq += [nodes_stops[node]]\n",
    "    return stops_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b44ac2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_route_id['stations sequence'] = [get_stops_sequence(route_id) for route_id in df_route_id.index]\n",
    "df_route_id['nodes sequence'] = [get_node_sequence(route_id) for route_id in df_route_id.index]\n",
    "df_route_id['nb stations'] = df_route_id['stations sequence'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ffa6009d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_route_type = pd.DataFrame(df_route_id.groupby('route_type')['stations sequence'].agg(lambda x: list(set(sum(x, [])))))\n",
    "stations_route_type['nb stations'] = stations_route_type['stations sequence'].apply(lambda x: len(x))\n",
    "df_route_type = df_route_type.merge(stations_route_type, left_on=df_route_type.index, right_on=stations_route_type.index, how='left')\n",
    "df_route_type = df_route_type.rename(columns={'key_0': 'route_type'})\n",
    "df_route_type = df_route_type.set_index('route_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1ea85a",
   "metadata": {},
   "source": [
    "## Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5549961a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterable = list(zip(nodes['stop_name'], nodes.index))\n",
    "\n",
    "stops_nodes = defaultdict(set)\n",
    "for key, value in iterable:\n",
    "    stops_nodes[key].add(value)\n",
    "stops_nodes = dict(stops_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2cacdef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterable = list(zip(links['a'], links['route_id']))\n",
    "iterable = iterable + list(zip(links['b'], links['route_id']))\n",
    "\n",
    "nodes_routes = defaultdict(set)\n",
    "for key, value in iterable:\n",
    "    nodes_routes[key].add(value)\n",
    "nodes_routes = dict(nodes_routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d314d997",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_routes = {}\n",
    "\n",
    "for stop, node_list in stops_nodes.items():\n",
    "    routes = set()\n",
    "    for node in node_list:\n",
    "        if node in nodes_routes:\n",
    "            routes.update(nodes_routes[node])\n",
    "    stops_routes[stop] = routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "074016b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hubs = pd.DataFrame.from_dict(stops_routes, orient='index')\n",
    "hubs['lines'] = hubs.apply(lambda row: [val for val in row if pd.notnull(val)], axis=1)\n",
    "hubs = hubs.drop(columns=[i for i in range(len(hubs.columns) - 1)])\n",
    "hubs['nb_lines'] = hubs['lines'].apply(lambda x: len(x))\n",
    "hubs = hubs.sort_values(by='nb_lines', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b639caa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_route_type = dict(zip(df_route_id.index, df_route_id['route_type']))\n",
    "dict_veh = dict(zip(df_route_id['route_type'], df_route_id['veh_capacity (PAX)']))\n",
    "route_order = sorted(dict_veh, key=lambda x: int(dict_veh[x]), reverse=True)\n",
    "\n",
    "def lines_to_dict(lines):\n",
    "    route_dict = {route_type: [] for route_type in route_order}\n",
    "    for line in lines:\n",
    "        route_type = dict_route_type.get(line)\n",
    "        if route_type in route_dict:\n",
    "            route_dict[route_type].append(line)\n",
    "    route_dict = {k: sorted(v) for k, v in route_dict.items() if v}\n",
    "    return route_dict\n",
    "\n",
    "hubs['lines'] = hubs['lines'].apply(lines_to_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "792c180d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.ops import unary_union\n",
    "\n",
    "def centroid(geometries):\n",
    "    combined_geometry = unary_union(geometries)\n",
    "    return combined_geometry.centroid\n",
    "\n",
    "centroids = pd.DataFrame(nodes.groupby('stop_name')['geometry'].agg(centroid))\n",
    "hubs = hubs.merge(centroids, left_on=hubs.index, right_on=centroids.index, how='left')\n",
    "\n",
    "hubs = hubs.rename(columns={'key_0': 'stop_name'})\n",
    "hubs = hubs.set_index('stop_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "feed3cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hubs['stop_radius'] = hubs['lines'].apply(lambda x: max(catchment_radius[mode] for mode in x.keys()))\n",
    "hubs['stop_radius'] = default_catchment_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ac08444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_connections(row):\n",
    "    route_id = row.name\n",
    "    connections = set()\n",
    "    for station in row['stations sequence']:\n",
    "        if station in stops_routes:\n",
    "            connections.update(stops_routes[station])\n",
    "    connections.discard(route_id)  # Supprimer la route_id de l'ensemble des connexions\n",
    "    return lines_to_dict(connections), len(connections)\n",
    "\n",
    "df_route_id[['connexions', 'nb lines connected']] = df_route_id.apply(lambda row: pd.Series(get_connections(row)), axis=1)\n",
    "\n",
    "# df_route_id[['connexions']].loc[df_route_id['connexions'] == 'tertiary']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7f7371",
   "metadata": {},
   "source": [
    "# Operational Fleet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6e408e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fleet_frequency(route_id):\n",
    "    link = links.loc[links['route_id'] == route_id].groupby(['route_id','trip_id'])[['time', 'frequency ph (veh/hour)']].agg({'time': np.nansum, 'frequency ph (veh/hour)': 'mean'})\n",
    "    link['fleet'] = np.ceil(link['frequency ph (veh/hour)'] * link['time'])\n",
    "    return link['fleet'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "09fdc895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188124"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_fleet_frequency('thiers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c485b13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fleet_timetable(route_id):\n",
    "    link = links.loc[links['route_id'] == route_id]\n",
    "    stations_sequence = df_route_id.loc[route_id]['nodes sequence']\n",
    "    circular_line = df_route_id.loc[route_id]['type'] == 'circular'\n",
    "\n",
    "    termini = [stations_sequence[0], stations_sequence[-1]]\n",
    "    link['a_terminus'] = link['a'].isin(termini)\n",
    "    link['b_terminus'] = link['b'].isin(termini)\n",
    "\n",
    "    if not circular_line:\n",
    "        dep0_times = link.loc[(link['trip_id'] == route_id + '_0') & link['a_terminus']]['departures'].values.tolist()[0]\n",
    "        dep1_times = link.loc[(link['trip_id'] == route_id + '_1') & link['a_terminus']]['departures'].values.tolist()[0]\n",
    "        arr0_times = link.loc[(link['trip_id'] == route_id + '_0') & link['b_terminus']]['arrivals'].values.tolist()[0]\n",
    "        arr1_times = link.loc[(link['trip_id'] == route_id + '_1') & link['b_terminus']]['arrivals'].values.tolist()[0]\n",
    "\n",
    "        dep0 = [time_seconds(t) for t in dep0_times]\n",
    "        dep1 = [time_seconds(t) for t in dep1_times]\n",
    "        arr0 = [time_seconds(t) for t in arr0_times]\n",
    "        arr1 = [time_seconds(t) for t in arr1_times]\n",
    "\n",
    "        travel_time0 = arr0[0] - dep0[0]\n",
    "        travel_time1 = arr1[0] - dep1[0]\n",
    "\n",
    "        nb_interbuses = []\n",
    "\n",
    "        for bus in dep0:\n",
    "            departure = bus\n",
    "            arrival = departure + travel_time0\n",
    "            if arrival < max(dep1):\n",
    "                departure_ = min([dep for dep in dep1 if dep>arrival])\n",
    "                tmax = departure_ + travel_time1\n",
    "            else:\n",
    "                tmax = max([max(dep0), max(arr1)])\n",
    "\n",
    "            t = bus\n",
    "            necessary_buses = 1\n",
    "            reserve_buses = 0\n",
    "            departures = [dep for dep in dep0 if dep>t]\n",
    "            arrivals = [arr for arr in arr1 if arr>t]\n",
    "\n",
    "            while t < tmax:\n",
    "                try:\n",
    "                    next_event = min([min(departures), min(arrivals)])\n",
    "                except ValueError:\n",
    "                    break\n",
    "                t=next_event\n",
    "                if (next_event in departures) and (next_event in arrivals):\n",
    "                    departures.pop(0)\n",
    "                    arrivals.pop(0)\n",
    "                    pass\n",
    "                elif next_event in departures:\n",
    "                    departures.pop(0)\n",
    "                    if reserve_buses >= 1:\n",
    "                        reserve_buses -= 1\n",
    "                    else:\n",
    "                        necessary_buses += 1\n",
    "                elif next_event in arrivals:\n",
    "                    arrivals.pop(0)\n",
    "                    necessary_buses += 1\n",
    "                    reserve_buses += 1\n",
    "\n",
    "            nb_interbuses.append(necessary_buses)\n",
    "\n",
    "        for bus in dep1:\n",
    "            departure = bus\n",
    "            arrival = departure + travel_time1\n",
    "            if arrival < max(dep0):\n",
    "                departure_ = min([dep for dep in dep0 if dep>arrival])\n",
    "                tmax = departure_ + travel_time0\n",
    "            else:\n",
    "                tmax = max([max(dep1), max(arr0)])\n",
    "\n",
    "            t = bus\n",
    "            necessary_buses = 1\n",
    "            reserve_buses = 0\n",
    "            departures = [dep for dep in dep1 if dep>t]\n",
    "            arrivals = [arr for arr in arr0 if arr>t]\n",
    "\n",
    "            while t < tmax:\n",
    "                try:\n",
    "                    next_event = min([min(departures), min(arrivals)])\n",
    "                except ValueError:\n",
    "                    break\n",
    "                t=next_event\n",
    "                if (next_event in departures) and (next_event in arrivals):\n",
    "                    departures.pop(0)\n",
    "                    arrivals.pop(0)\n",
    "                    pass\n",
    "                elif next_event in departures:\n",
    "                    departures.pop(0)\n",
    "                    if reserve_buses >= 1:\n",
    "                        reserve_buses -= 1\n",
    "                    else:\n",
    "                        necessary_buses += 1\n",
    "                elif next_event in arrivals:\n",
    "                    arrivals.pop(0)\n",
    "                    necessary_buses += 1\n",
    "                    reserve_buses += 1\n",
    "\n",
    "            nb_interbuses.append(necessary_buses)\n",
    "    \n",
    "    else:\n",
    "        dep0_times = link.loc[(link['trip_id'] == route_id + '_0') & link['a_terminus']]['departures'].values.tolist()[0]\n",
    "        arr0_times = link.loc[(link['trip_id'] == route_id + '_0') & link['b_terminus']]['arrivals'].values.tolist()[0]\n",
    "\n",
    "        dep0 = [time_seconds(t) for t in dep0_times]\n",
    "        arr0 = [time_seconds(t) for t in arr0_times]\n",
    "\n",
    "        travel_time0 = arr0[0] - dep0[0]\n",
    "\n",
    "        nb_interbuses = []\n",
    "        for bus in dep0:\n",
    "            departure = bus\n",
    "            arrival = departure + travel_time0\n",
    "            n_buses = len([dep for dep in dep0 if (dep>=bus and dep<arrival)])\n",
    "            nb_interbuses.append(n_buses)\n",
    "\n",
    "    return max(max(nb_interbuses), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e79fd723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_service_hours_timetable(route_id):\n",
    "    link = links.loc[links['route_id'] == route_id]\n",
    "    stations_sequence = df_route_id.loc[route_id]['nodes sequence']\n",
    "    circular_line = df_route_id.loc[route_id]['type'] == 'circular'\n",
    "\n",
    "    termini = [stations_sequence[0], stations_sequence[-1]]\n",
    "    link['a_terminus'] = link['a'].isin(termini)\n",
    "    link['b_terminus'] = link['b'].isin(termini)\n",
    "\n",
    "    if not circular_line:\n",
    "        dep0_times = link.loc[(link['trip_id'] == route_id + '_0') & link['a_terminus']]['departures'].values.tolist()[0]\n",
    "        dep1_times = link.loc[(link['trip_id'] == route_id + '_1') & link['a_terminus']]['departures'].values.tolist()[0]\n",
    "        arr0_times = link.loc[(link['trip_id'] == route_id + '_0') & link['b_terminus']]['arrivals'].values.tolist()[0]\n",
    "        arr1_times = link.loc[(link['trip_id'] == route_id + '_1') & link['b_terminus']]['arrivals'].values.tolist()[0]\n",
    "\n",
    "        dep0 = [time_seconds(t) for t in dep0_times]\n",
    "        dep1 = [time_seconds(t) for t in dep1_times]\n",
    "        arr0 = [time_seconds(t) for t in arr0_times]\n",
    "        arr1 = [time_seconds(t) for t in arr1_times]\n",
    "\n",
    "        time_range = np.ceil((max([max(arr0), max(arr1)]) - min([min(dep0), min(dep1)]))/3600)\n",
    "\n",
    "    return time_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "720618f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "links.loc[links['line_has_timetable']==1, 'fleet'] = links.loc[links['line_has_timetable']==1, 'route_id'].apply(get_fleet_timetable)\n",
    "links.loc[links['line_has_timetable']==1, 'nb_service_hours'] = links.loc[links['line_has_timetable']==1, 'route_id'].apply(get_service_hours_timetable)\n",
    "\n",
    "links.loc[links['line_has_timetable']==0, 'fleet'] = links.loc[links['line_has_timetable']==0, 'route_id'].apply(get_fleet_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "723df21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (links.groupby('trip_id')['nb_service_hours'].agg('mean')).to_dict()\n",
    "df_trip_id['nb_service_hours'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7747777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (links.groupby('route_id')['fleet'].agg('mean')).to_dict()\n",
    "df_route_id['fleet'] = res\n",
    "\n",
    "res = (links.groupby('route_id')['nb_service_hours'].agg('mean')).to_dict()\n",
    "df_route_id['nb_service_hours'] = res\n",
    "\n",
    "df_route_id['frequency (veh/hour)'] = df_route_id['frequency (veh/day)'] / df_route_id['nb_service_hours']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f4af8692",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = df_route_id.reset_index().groupby('route_type')['fleet'].agg('sum').to_dict()\n",
    "df_route_type['fleet'] = res\n",
    "\n",
    "res = df_route_id.reset_index().groupby('route_type')['nb_service_hours'].agg('max').to_dict()\n",
    "df_route_type['nb_service_hours'] = res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f98a64c",
   "metadata": {},
   "source": [
    "# Operating costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c70257d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequency = freq moy jour\n",
    "def get_veh_kmh(col='route_id', length_col='length'):\n",
    "    link = links.groupby([col, 'trip_id'])[[length_col, 'frequency_per_day', 'nb_service_hours']].agg({length_col:'sum', 'frequency_per_day': 'mean', 'nb_service_hours': 'mean'})\n",
    "    link['veh_km/h'] = np.ceil(link['frequency_per_day'] * link[length_col]) / 1000 / link['nb_service_hours'] #to km/H\n",
    "    return link.reset_index().groupby(col)['veh_km/h'].agg('sum').to_dict()\n",
    "\n",
    "def get_veh_km(col='route_id', length_col='length'):\n",
    "    link = links.groupby([col, 'trip_id'])[[length_col, 'frequency_per_day', 'nb_service_hours']].agg({length_col:'sum', 'frequency_per_day': 'mean', 'nb_service_hours': 'mean'})\n",
    "    link['veh_km/h'] = np.ceil(link['frequency_per_day'] * link[length_col]) / 1000  #to km/H\n",
    "    return link.reset_index().groupby(col)['veh_km/h'].agg('sum').to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7677d391",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_veh_km('route_id', 'length')\n",
    "df_route_id['veh_km_day'] = res\n",
    "df_route_id['veh_km_year'] = df_route_id['veh_km_day'] * coef_day_to_year\n",
    "\n",
    "res = links.groupby('route_id')['capex'].agg('mean').to_dict()\n",
    "df_route_id['capex'] = res\n",
    "\n",
    "df_route_id['vehicle_cost_km_day'] = df_route_id['veh_km_day'] * df_route_id['capex']\n",
    "df_route_id['vehicle_cost_km_year'] = df_route_id['vehicle_cost_km_day'] * coef_day_to_year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab77743f",
   "metadata": {},
   "source": [
    "# Round trip time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fd818c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_round_trip_time(col='route_id'):\n",
    "    link = links.groupby([col,'trip_id'])[['time']].agg('sum')\n",
    "    return link.reset_index().groupby(col)['time'].agg('sum').to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "869ea67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_round_trip_time('route_id')\n",
    "\n",
    "df_route_id['round trip time (s)'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "567d2645",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_route_id['speed (km/h)'] = df_route_id['length (m)'] / df_route_id['round trip time (s)'] * 3.6\n",
    "df_route_id['length (km)'] = df_route_id['length (m)'] / 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5213bf",
   "metadata": {},
   "source": [
    "# Export results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7948cbd",
   "metadata": {},
   "source": [
    "## Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9250e0f1",
   "metadata": {},
   "source": [
    "### Characterstics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3a1861cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['route_type', \n",
    "           'nb stations', \n",
    "           'length (km)', \n",
    "           'speed (km/h)', \n",
    "           'frequency (veh/day)', \n",
    "           'veh_capacity (PAX)', \n",
    "           'veh_km_year', \n",
    "           'vehicle_cost_km_year',\n",
    "           'geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "40caa102",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_table = df_route_id.copy()[columns]\n",
    "char_table['length (km)'] = char_table['length (km)'].apply(np.round, decimals=1)\n",
    "char_table['speed (km/h)'] = char_table['speed (km/h)'].apply(np.round, decimals=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "350c24ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_table.to_csv(output_folder + 'lines_chacteristics.csv')\n",
    "\n",
    "char_table_geo = gpd.GeoDataFrame(char_table, geometry='geometry', crs='EPSG:4326')\n",
    "char_table_geo.to_file(output_folder + 'lines_chacteristics.geojson', driver='GeoJSON', engine=io_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d395489c",
   "metadata": {},
   "source": [
    "### Catchment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e357b4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "catchment_columns = [col for col in df_route_id.columns if 'catchment' in col]\n",
    "catchment_columns_ = catchment_columns + ['geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e0d85139",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch_table = df_route_id.copy()[catchment_columns_]\n",
    "for col in catchment_columns:\n",
    "    catch_table[col] = catch_table[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cddfc42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch_table.to_csv(output_folder + 'lines_catchment.csv')\n",
    "\n",
    "catch_table_geo = gpd.GeoDataFrame(catch_table, geometry='geometry', crs='EPSG:4326')\n",
    "catch_table_geo.to_file(output_folder + 'lines_catchment.geojson', driver='GeoJSON', engine=io_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "37b8d896",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO : formater les tableaux de sortie de df_route_id ==> caractéristiques / accessibilité / réponse au besoin\n",
    "\n",
    "# Dans réponse au besoin : estimation du volume de flux TC desservis sans correspondance pour une PM de 20%, estimation du taux de remplissage TC sans correspondance pour une PM TC de 10%\n",
    "\n",
    "#TODO: ajouter les tableaux globaux df_route_type (longueur totale, nombre de stations, flotte, veh.km/jour, capex/jour, veh.km/an, capex/an) et hubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4a7d0d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# round numbers\n",
    "#TODO : change label catchment\n",
    "# for col in ['catchment population', 'frequency (veh/hours)','length (m)','veh.km/h','round trip time (s)']:\n",
    "#     df_route_id[col] = df_route_id[col].apply(lambda x :np.round(x,2))\n",
    "#     df_route_id[col] = df_route_id[col].apply(lambda x :np.round(x,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3105f92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_route_id = df_route_id.fillna('null')\n",
    "#df_route_type = df_route_type.fillna('null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "984694c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_route_id.to_csv(output_folder + 'route_id_metrics.csv')\n",
    "# df_route_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c6a5c283",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_route_type.to_csv(output_folder + 'route_type_metrics.csv')\n",
    "# df_route_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1a948d",
   "metadata": {},
   "source": [
    "## Geomatic outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dcea6b",
   "metadata": {},
   "source": [
    "Hubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "395318b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hubs_plot = hubs.copy()\n",
    "hubs_plot['lines'] = hubs_plot['lines'].apply(lambda x: str(x).replace(',', ';').replace(\"'\", '')[1:-1])\n",
    "hubs_plot.to_csv(output_folder + 'hubs.csv')\n",
    "\n",
    "hubs = gpd.GeoDataFrame(hubs, geometry='geometry', crs='EPSG:4326')\n",
    "hubs.to_file(output_folder + 'hubs.geojson', driver='GeoJSON', engine=io_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b22e89",
   "metadata": {},
   "source": [
    "Common sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2cf546b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renvoie un fichier geojson avec les tronçons en commun entre plusieurs lignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8ad927d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering de 500m pour a et b et cluster d'appartenance\n",
    "coords_nodes = np.array(nodes['geometry'].apply(lambda point: (point.x, point.y)).tolist())\n",
    "\n",
    "# Convertir 500 mètres en degrés : 111 km = 1 degré de latitude\n",
    "eps_lat = clustering_radius / (111 * 1000)  # Environ 0.0045 degrés\n",
    "\n",
    "# 1 degré de longitude dépend de la latitude\n",
    "mean_latitude = np.mean(coords_nodes[:, 1])\n",
    "eps_lon = clustering_radius / (111 * 1000 * np.cos(np.radians(mean_latitude)))\n",
    "\n",
    "# Appliquer DBSCAN avec une distance euclidienne pondérée\n",
    "db = DBSCAN(eps=1, min_samples=1, metric='euclidean').fit(coords_nodes / [eps_lon, eps_lat])\n",
    "\n",
    "# Ajouter les labels de cluster au GeoDataFrame\n",
    "nodes['cluster'] = db.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "de33553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = nodes.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "605b754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = links.merge(nodes[['index', 'cluster']], left_on='a', right_on='index', how='left').drop(columns='index').rename(columns={'cluster': 'a_clustered'})\n",
    "links = links.merge(nodes[['index', 'cluster']], left_on='b', right_on='index', how='left').drop(columns='index').rename(columns={'cluster': 'b_clustered'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "43462dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_troncons = links.groupby(['a_clustered', 'b_clustered'])['route_id'].agg(list).reset_index()\n",
    "l_troncons['nb_lines'] = l_troncons['route_id'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7a122690",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_troncons_communs = l_troncons[l_troncons.nb_lines > 1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2f63f1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "troncons_communs = len(l_troncons_communs) > 0.\n",
    "print(troncons_communs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "77eaadb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if troncons_communs:\n",
    "    l_troncons_communs['geometry'] = l_troncons_communs.apply(\n",
    "        lambda row : links[(links.a_clustered == row['a_clustered']) & (links.b_clustered == row['b_clustered'])].drop_duplicates(subset=['a_clustered', 'b_clustered'], keep='first').geometry.values[0],\n",
    "        axis=1\n",
    "        )\n",
    "    l_troncons_communs['stations_a'] = l_troncons_communs['a_clustered'].apply(lambda x: list(nodes[nodes.cluster == x]['stop_name'].unique()))\n",
    "    l_troncons_communs['stations_b'] = l_troncons_communs['b_clustered'].apply(lambda x: list(nodes[nodes.cluster == x]['stop_name'].unique()))\n",
    "    l_troncons_communs = gpd.GeoDataFrame(l_troncons_communs[['stations_a', 'stations_b', 'route_id', 'nb_lines', 'geometry']], geometry='geometry', crs='EPSG:4326')\n",
    "    l_troncons_communs.to_file(output_folder + 'pt_common_sections.geojson', driver='GeoJSON', engine=io_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372bb5bd",
   "metadata": {},
   "source": [
    "df_route_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "02ddd7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_type</th>\n",
       "      <th>veh_capacity (PAX)</th>\n",
       "      <th>headway</th>\n",
       "      <th>headway_ph</th>\n",
       "      <th>headway_oph</th>\n",
       "      <th>nb_peak_hours</th>\n",
       "      <th>geometry</th>\n",
       "      <th>catchment population car</th>\n",
       "      <th>catchment population walk</th>\n",
       "      <th>catchment population bike</th>\n",
       "      <th>frequency (veh/day)</th>\n",
       "      <th>frequency (veh/hour)</th>\n",
       "      <th>frequency ph (veh/hour)</th>\n",
       "      <th>frequency oph (veh/hour)</th>\n",
       "      <th>length (m)</th>\n",
       "      <th>type</th>\n",
       "      <th>stations sequence</th>\n",
       "      <th>nodes sequence</th>\n",
       "      <th>nb stations</th>\n",
       "      <th>connexions</th>\n",
       "      <th>nb lines connected</th>\n",
       "      <th>fleet</th>\n",
       "      <th>nb_service_hours</th>\n",
       "      <th>veh_km_day</th>\n",
       "      <th>veh_km_year</th>\n",
       "      <th>capex</th>\n",
       "      <th>vehicle_cost_km_day</th>\n",
       "      <th>vehicle_cost_km_year</th>\n",
       "      <th>round trip time (s)</th>\n",
       "      <th>speed (km/h)</th>\n",
       "      <th>length (km)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>route_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>thiers</th>\n",
       "      <td>bus</td>\n",
       "      <td>60.0</td>\n",
       "      <td>600</td>\n",
       "      <td>300</td>\n",
       "      <td>900</td>\n",
       "      <td>14.0</td>\n",
       "      <td>MULTILINESTRING ((3.101473 45.7798, 3.100768 4...</td>\n",
       "      <td>4276.141472</td>\n",
       "      <td>949.484239</td>\n",
       "      <td>2497.464585</td>\n",
       "      <td>160.0</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>43546.0</td>\n",
       "      <td>linear</td>\n",
       "      <td>[Clermont Gare, Ornon, Thiers]</td>\n",
       "      <td>[node_sAN6V1B3jeCqCFXoE6x1vn, node_fgmxDaNaU6d...</td>\n",
       "      <td>3</td>\n",
       "      <td>{'bus': ['blanzat', 'riom', 'saint_sauves_auve...</td>\n",
       "      <td>3</td>\n",
       "      <td>188124.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13934.72</td>\n",
       "      <td>4180416.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4180.416</td>\n",
       "      <td>1254124.8</td>\n",
       "      <td>15677</td>\n",
       "      <td>9.999719</td>\n",
       "      <td>43.5460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saint_sauves_auvergne</th>\n",
       "      <td>bus</td>\n",
       "      <td>60.0</td>\n",
       "      <td>600</td>\n",
       "      <td>300</td>\n",
       "      <td>900</td>\n",
       "      <td>14.0</td>\n",
       "      <td>MULTILINESTRING ((2.690068 45.605999, 2.690089...</td>\n",
       "      <td>2811.517958</td>\n",
       "      <td>1270.115553</td>\n",
       "      <td>2026.623100</td>\n",
       "      <td>160.0</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44972.0</td>\n",
       "      <td>linear</td>\n",
       "      <td>[Saint-Sauves, Rochefort-Montagne, Quatre-Rout...</td>\n",
       "      <td>[node_2wm9Y7Vs2WfWmoUbPRKZKQ, node_m4uoHRPvZrR...</td>\n",
       "      <td>4</td>\n",
       "      <td>{'bus': ['blanzat', 'riom', 'thiers']}</td>\n",
       "      <td>3</td>\n",
       "      <td>194280.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14391.04</td>\n",
       "      <td>4317312.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4317.312</td>\n",
       "      <td>1295193.6</td>\n",
       "      <td>16190</td>\n",
       "      <td>9.999951</td>\n",
       "      <td>44.9720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>riom</th>\n",
       "      <td>bus</td>\n",
       "      <td>60.0</td>\n",
       "      <td>600</td>\n",
       "      <td>300</td>\n",
       "      <td>900</td>\n",
       "      <td>14.0</td>\n",
       "      <td>MULTILINESTRING ((3.101543 45.779832, 3.100768...</td>\n",
       "      <td>54054.967853</td>\n",
       "      <td>4699.302754</td>\n",
       "      <td>24064.563772</td>\n",
       "      <td>160.0</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13816.0</td>\n",
       "      <td>linear</td>\n",
       "      <td>[Clermont Gare, Croix-de-Neyrat, Riom]</td>\n",
       "      <td>[node_6rQtn2pem68ouRZNB8hBMS, node_7St5cKstGjL...</td>\n",
       "      <td>3</td>\n",
       "      <td>{'bus': ['blanzat', 'saint_sauves_auvergne', '...</td>\n",
       "      <td>3</td>\n",
       "      <td>59676.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4421.12</td>\n",
       "      <td>1326336.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1326.336</td>\n",
       "      <td>397900.8</td>\n",
       "      <td>4973</td>\n",
       "      <td>10.001528</td>\n",
       "      <td>13.8160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blanzat</th>\n",
       "      <td>bus</td>\n",
       "      <td>60.0</td>\n",
       "      <td>600</td>\n",
       "      <td>300</td>\n",
       "      <td>900</td>\n",
       "      <td>14.0</td>\n",
       "      <td>MULTILINESTRING ((3.101451 45.779789, 3.100768...</td>\n",
       "      <td>60715.009029</td>\n",
       "      <td>5299.830330</td>\n",
       "      <td>30762.442344</td>\n",
       "      <td>160.0</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9731.5</td>\n",
       "      <td>linear</td>\n",
       "      <td>[Clermont Gare, Croix-de-Neyrat, Cébazat, Blan...</td>\n",
       "      <td>[node_vh4NDiGoT7GmhVDuxKtfwy, node_jXrQhUo8hu7...</td>\n",
       "      <td>4</td>\n",
       "      <td>{'bus': ['riom', 'saint_sauves_auvergne', 'thi...</td>\n",
       "      <td>3</td>\n",
       "      <td>42048.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3114.08</td>\n",
       "      <td>934224.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>934.224</td>\n",
       "      <td>280267.2</td>\n",
       "      <td>3504</td>\n",
       "      <td>9.998116</td>\n",
       "      <td>9.7315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      route_type  veh_capacity (PAX)  headway  headway_ph  \\\n",
       "route_id                                                                    \n",
       "thiers                       bus                60.0      600         300   \n",
       "saint_sauves_auvergne        bus                60.0      600         300   \n",
       "riom                         bus                60.0      600         300   \n",
       "blanzat                      bus                60.0      600         300   \n",
       "\n",
       "                       headway_oph  nb_peak_hours  \\\n",
       "route_id                                            \n",
       "thiers                         900           14.0   \n",
       "saint_sauves_auvergne          900           14.0   \n",
       "riom                           900           14.0   \n",
       "blanzat                        900           14.0   \n",
       "\n",
       "                                                                geometry  \\\n",
       "route_id                                                                   \n",
       "thiers                 MULTILINESTRING ((3.101473 45.7798, 3.100768 4...   \n",
       "saint_sauves_auvergne  MULTILINESTRING ((2.690068 45.605999, 2.690089...   \n",
       "riom                   MULTILINESTRING ((3.101543 45.779832, 3.100768...   \n",
       "blanzat                MULTILINESTRING ((3.101451 45.779789, 3.100768...   \n",
       "\n",
       "                       catchment population car  catchment population walk  \\\n",
       "route_id                                                                     \n",
       "thiers                              4276.141472                 949.484239   \n",
       "saint_sauves_auvergne               2811.517958                1270.115553   \n",
       "riom                               54054.967853                4699.302754   \n",
       "blanzat                            60715.009029                5299.830330   \n",
       "\n",
       "                       catchment population bike  frequency (veh/day)  \\\n",
       "route_id                                                                \n",
       "thiers                               2497.464585                160.0   \n",
       "saint_sauves_auvergne                2026.623100                160.0   \n",
       "riom                                24064.563772                160.0   \n",
       "blanzat                             30762.442344                160.0   \n",
       "\n",
       "                       frequency (veh/hour)  frequency ph (veh/hour)  \\\n",
       "route_id                                                               \n",
       "thiers                            13.333333                     12.0   \n",
       "saint_sauves_auvergne             13.333333                     12.0   \n",
       "riom                              13.333333                     12.0   \n",
       "blanzat                           13.333333                     12.0   \n",
       "\n",
       "                       frequency oph (veh/hour)  length (m)    type  \\\n",
       "route_id                                                              \n",
       "thiers                                      4.0     43546.0  linear   \n",
       "saint_sauves_auvergne                       4.0     44972.0  linear   \n",
       "riom                                        4.0     13816.0  linear   \n",
       "blanzat                                     4.0      9731.5  linear   \n",
       "\n",
       "                                                       stations sequence  \\\n",
       "route_id                                                                   \n",
       "thiers                                    [Clermont Gare, Ornon, Thiers]   \n",
       "saint_sauves_auvergne  [Saint-Sauves, Rochefort-Montagne, Quatre-Rout...   \n",
       "riom                              [Clermont Gare, Croix-de-Neyrat, Riom]   \n",
       "blanzat                [Clermont Gare, Croix-de-Neyrat, Cébazat, Blan...   \n",
       "\n",
       "                                                          nodes sequence  \\\n",
       "route_id                                                                   \n",
       "thiers                 [node_sAN6V1B3jeCqCFXoE6x1vn, node_fgmxDaNaU6d...   \n",
       "saint_sauves_auvergne  [node_2wm9Y7Vs2WfWmoUbPRKZKQ, node_m4uoHRPvZrR...   \n",
       "riom                   [node_6rQtn2pem68ouRZNB8hBMS, node_7St5cKstGjL...   \n",
       "blanzat                [node_vh4NDiGoT7GmhVDuxKtfwy, node_jXrQhUo8hu7...   \n",
       "\n",
       "                       nb stations  \\\n",
       "route_id                             \n",
       "thiers                           3   \n",
       "saint_sauves_auvergne            4   \n",
       "riom                             3   \n",
       "blanzat                          4   \n",
       "\n",
       "                                                              connexions  \\\n",
       "route_id                                                                   \n",
       "thiers                 {'bus': ['blanzat', 'riom', 'saint_sauves_auve...   \n",
       "saint_sauves_auvergne             {'bus': ['blanzat', 'riom', 'thiers']}   \n",
       "riom                   {'bus': ['blanzat', 'saint_sauves_auvergne', '...   \n",
       "blanzat                {'bus': ['riom', 'saint_sauves_auvergne', 'thi...   \n",
       "\n",
       "                       nb lines connected     fleet  nb_service_hours  \\\n",
       "route_id                                                                \n",
       "thiers                                  3  188124.0              12.0   \n",
       "saint_sauves_auvergne                   3  194280.0              12.0   \n",
       "riom                                    3   59676.0              12.0   \n",
       "blanzat                                 3   42048.0              12.0   \n",
       "\n",
       "                       veh_km_day  veh_km_year  capex  vehicle_cost_km_day  \\\n",
       "route_id                                                                     \n",
       "thiers                   13934.72    4180416.0    0.3             4180.416   \n",
       "saint_sauves_auvergne    14391.04    4317312.0    0.3             4317.312   \n",
       "riom                      4421.12    1326336.0    0.3             1326.336   \n",
       "blanzat                   3114.08     934224.0    0.3              934.224   \n",
       "\n",
       "                       vehicle_cost_km_year  round trip time (s)  \\\n",
       "route_id                                                           \n",
       "thiers                            1254124.8                15677   \n",
       "saint_sauves_auvergne             1295193.6                16190   \n",
       "riom                               397900.8                 4973   \n",
       "blanzat                            280267.2                 3504   \n",
       "\n",
       "                       speed (km/h)  length (km)  \n",
       "route_id                                          \n",
       "thiers                     9.999719      43.5460  \n",
       "saint_sauves_auvergne      9.999951      44.9720  \n",
       "riom                      10.001528      13.8160  \n",
       "blanzat                    9.998116       9.7315  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_route_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "13abf2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd.GeoDataFrame(df_route_id, geometry='geometry').to_file(output_folder + 'pt_network_kpis.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3ebbf6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_route_id to geojson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6559846b",
   "metadata": {},
   "source": [
    "Nodes catchment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "01bc6f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO pcq c'est DYNAMIQUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "10166c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using get catchment : get the catchment radius of each node (get larger one if used by many modes)\n",
    "for col in catchment_radii:\n",
    "    suf = col.split('catchment_radius_')[1]\n",
    "    for density in densities:\n",
    "        if density == 'density' and 'population_density' not in densities:\n",
    "            tag = 'population'\n",
    "        elif density == 'density':\n",
    "            tag = 'x'\n",
    "        else:\n",
    "            tag = density.split('_density')[0]\n",
    "\n",
    "        mesh, node_dist = meshes[tag], node_dists[tag]\n",
    "\n",
    "        link = links.groupby('route_type')[['a', 'b', 'route_type', col]].agg({'a': set, 'b': set, 'route_type': 'first', col:np.nanmean})\n",
    "        link['node'] = link.apply(lambda row: row['a'].union(row['b']), axis=1)\n",
    "        link = link.drop(columns=['a','b'])\n",
    "        ## add catchment radius for the route_type\n",
    "        link = link.explode('node').reset_index(drop=True)\n",
    "        link = link.sort_values(col,ascending=False).drop_duplicates('node',keep='first')\n",
    "        link = node_dist.merge(link, left_on='node_index', right_on='node')\n",
    "        link = link[link['distances'] <= link[col]]\n",
    "\n",
    "        temp_dict = link.groupby('node_index')[tag].sum().to_dict()\n",
    "        nodes['catchment {} {}'.format(suf, tag)] = nodes['index'].map(temp_dict.get)\n",
    "\n",
    "        temp_dict = link.groupby('node_index')[col].agg('first').to_dict() \n",
    "        nodes[col] = nodes['index'].map(temp_dict.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4460bb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.to_file(output_folder + 'nodes.geojson', driver='GeoJSON', engine=io_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204675d1",
   "metadata": {},
   "source": [
    "## Graphs and pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ba0c4f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot = df_route_type.reset_index().plot(kind='bar', x='route_type', y='catchment', color='#559bb4', rot=0, figsize=[10, 5])\n",
    "# plot.set_title('Couverture population par mode')\n",
    "# plot.set_ylabel('')\n",
    "# plot.set_xlabel(\"route_type\")\n",
    "# plot.legend([])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
