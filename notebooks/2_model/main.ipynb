{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "71ccff01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training_folder': '../../scenarios/clermont', 'params': {'general': {'step_size': '0.001', 'use_road_network': True, 'coef_day_to_year': '300', 'clustering_radius': '500'}}}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "\n",
    "general = {'step_size': '0.001', 'use_road_network': True, 'coef_day_to_year': '300', 'clustering_radius': '500'}\n",
    "\n",
    "params = {\n",
    "    'general': general,\n",
    "    }\n",
    "\n",
    "default = {'training_folder': '../../scenarios/clermont', 'params':params} # Default execution parameters\n",
    "manual, argv = (True, default) if 'ipykernel' in sys.argv[0] else (False, dict(default, **json.loads(sys.argv[1])))\n",
    "print(argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "99b5db61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numba threads 16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "sys.path.insert(0, r'../../../quetzal') # Add path to quetzal\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point, LineString\n",
    "from typing import Literal\n",
    "import numba as nb\n",
    "from collections import defaultdict\n",
    "from sklearn.cluster import DBSCAN\n",
    "#num_cores = 1\n",
    "print('numba threads',nb.config.NUMBA_NUM_THREADS)\n",
    "\n",
    "on_lambda = bool(os.environ.get('AWS_EXECUTION_ENV'))\n",
    "io_engine = 'pyogrio' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "772a187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, r'../../') # Add path\n",
    "from utils import get_epsg, population_to_mesh, get_acf_distances, get_routing_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c740a4",
   "metadata": {},
   "source": [
    "# Folders stucture and params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbbcb7a",
   "metadata": {},
   "source": [
    "Everything is on S3 (nothing on ECR) so no direct input folder. just scenarios/{scen}/inputs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "8ade8441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../scenarios/clermont'"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argv['training_folder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "d16ff565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'general': {'step_size': '0.001',\n",
       "  'use_road_network': True,\n",
       "  'coef_day_to_year': '300',\n",
       "  'clustering_radius': '500'}}"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argv['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "4e405b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = argv['training_folder']\n",
    "input_folder = os.path.join(base_folder,'inputs/')\n",
    "pt_folder  = os.path.join(input_folder,'pt/')\n",
    "road_folder = os.path.join(input_folder,'road/') ## réseau ferré\n",
    "od_folder =  os.path.join(input_folder,'od/')\n",
    "\n",
    "output_folder = os.path.join(base_folder,'outputs/')\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "model_folder = os.path.join(input_folder, 'model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "81b11c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read general params\n",
    "step_size_min = 0.0005\n",
    "step_size = max(float(argv['params']['general'].get('step_size')), step_size_min)\n",
    "use_road_network = argv['params']['general'].get('use_road_network') ## param use r_ntw\n",
    "coef_day_to_year = float(argv['params']['general'].get('coef_day_to_year'))\n",
    "clustering_radius = float(argv['params']['general'].get('clustering_radius'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "9d656677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default pt_links params in case not filled by the user\n",
    "default_catchment_radius = 500      # meters\n",
    "default_capex = 0.3                 # €/veh.km\n",
    "default_capacity = 60               # vehicle capacity in PAX\n",
    "default_service_hours = 12          # nb d'heures par jour de fonctionnement\n",
    "#ajouter : nb heures service/jour / headway (mais il y est déjà)\n",
    "#TODO: voir si on peut ajouter les champs défaut dans les liens ==> suppr. ==> adapter script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd032bd",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bacf9ca",
   "metadata": {},
   "source": [
    "PT links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "5b5ada42",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pt_folder + 'links.geojson') as f:\n",
    "    links_ = json.load(f)\n",
    "\n",
    "columns = set()\n",
    "for feature in links_['features']:\n",
    "    for key in feature['properties'].keys():\n",
    "        columns.add(key)\n",
    "\n",
    "links = pd.DataFrame(links_['features'])\n",
    "for col in columns:\n",
    "    links[col] = links.apply(lambda x: x['properties'].get(col, None), 1)\n",
    "links['geometry'] = links['geometry'].apply(lambda x: LineString(x['coordinates']))\n",
    "links.drop(columns=['type', 'properties'], inplace=True)\n",
    "\n",
    "links = links.set_index('index')\n",
    "links = gpd.GeoDataFrame(links, geometry='geometry', crs='EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "1a674100",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = gpd.read_file(pt_folder + 'nodes.geojson', engine=io_engine)\n",
    "nodes = nodes.set_index('index')\n",
    "nodes = nodes[~pd.isna(nodes.geometry)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "ae761b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# links['catchment_radius_marche'] = 800\n",
    "# links['catchment_radius_velo'] = 3000\n",
    "# links['catchment_radius_voiture'] = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "21d54c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'capacity' not in links.columns:\n",
    "    links['capacity'] = default_capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "921a0d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'capex' not in links.columns:\n",
    "    links['capex'] = default_capex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "daa5b7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "catchment_radii = [x for x in links.columns if 'catchment_radius' in x]\n",
    "catchment_radii_provided = (len(catchment_radii) > 0)\n",
    "if catchment_radii_provided:\n",
    "    for x in catchment_radii:\n",
    "        M = links[x].max()\n",
    "        if not links[x].equals(links[x].fillna(M)):\n",
    "            print('!! Catchemnt radius values missing in column {} !!'.format(x))\n",
    "        links[x] = links[x].fillna(M)\n",
    "else:\n",
    "    links['catchment_radius'] = default_catchment_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "642dc9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_service_hours = 12\n",
    "if 'nb_service_hours' not in links.columns:\n",
    "    links['nb_service_hours'] = default_service_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "47cc208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'departures' not in links.columns:\n",
    "    links['departures'] = None\n",
    "if 'arrivals' not in links.columns:\n",
    "    links['arrivals'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331a0486",
   "metadata": {},
   "source": [
    "Input data zoning file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "0d6324e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32631"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find meters CRS\n",
    "centroid = [*LineString(nodes.centroid.values).centroid.coords][0]\n",
    "crs = get_epsg(centroid[1],centroid[0])\n",
    "crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "99e4e06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zonage_file = os.path.join(input_folder, 'zonage.geojson')\n",
    "zonage_file_provided = os.path.isfile(zonage_file)\n",
    "if zonage_file_provided :\n",
    "    zonage = gpd.read_file(input_folder + 'zonage.geojson', engine=io_engine).to_crs(epsg='4326')\n",
    "    zonage['area (km2)'] = zonage.to_crs(crs).area / 10**6\n",
    "else:\n",
    "    print('No zonage file in the input folder...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "4ad58e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "densities = [x for x in zonage.columns if 'density' in x]\n",
    "assert len(densities) > 0, 'Please provide densities as input data in the zoning file'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "36a141e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_ph_columns = ('headway_ph' in links.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69419eeb",
   "metadata": {},
   "source": [
    "Road network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "ac965c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "road network ? True\n"
     ]
    }
   ],
   "source": [
    "## road network here\n",
    "rnodes_file = os.path.join(road_folder, 'road_nodes.geojson')\n",
    "rnodes_file_provided = os.path.isfile(rnodes_file)\n",
    "if rnodes_file_provided:\n",
    "    rnodes = gpd.read_file(os.path.join(road_folder, 'road_nodes.geojson'), engine=io_engine)\n",
    "    rnodes = rnodes.set_index('index').to_crs(epsg='4326')\n",
    "    rlinks = gpd.read_file(os.path.join(road_folder, 'road_links.geojson'), engine=io_engine)\n",
    "    rlinks = rlinks.set_index('index').to_crs(epsg='4326')\n",
    "print('road network ?',rnodes_file_provided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "6071cbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "od ? False\n"
     ]
    }
   ],
   "source": [
    "od_file = os.path.join(od_folder, 'od.geojson')\n",
    "od_file_provided = os.path.isfile(od_file)\n",
    "if od_file_provided:\n",
    "    od_test = gpd.read_file(od_file, engine=io_engine)\n",
    "    if 'name' not in od_test.columns:\n",
    "        od_test['name'] = od_test['index']\n",
    "    od_test['name'] = od_test['name'].fillna(od_test['index'].astype(str))\n",
    "print('od ?',od_file_provided)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0687074a",
   "metadata": {},
   "source": [
    "# Init result dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "4cf77ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_route_id = pd.DataFrame(index=links['route_id'].unique())\n",
    "df_route_id.index.name = 'route_id'\n",
    "df_route_id = df_route_id.reset_index()\n",
    "if display_ph_columns:   \n",
    "    df_route_id = df_route_id.merge(links[['route_id', 'route_type', 'capacity', 'headway', 'headway_ph', 'headway_oph', 'nb_peak_hours']], on='route_id', how='left')\n",
    "else:\n",
    "    df_route_id = df_route_id.merge(links[['route_id', 'route_type', 'capacity', 'headway']], on='route_id', how='left')\n",
    "df_route_id = df_route_id.rename(columns={'capacity': 'veh_capacity (PAX)'})\n",
    "df_route_id = df_route_id.drop_duplicates()\n",
    "df_route_id = df_route_id.set_index('route_id')\n",
    "\n",
    "df_trip_id = pd.DataFrame(index=links['trip_id'].unique())\n",
    "df_trip_id.index.name = 'trip_id'\n",
    "df_trip_id = df_trip_id.reset_index()\n",
    "if display_ph_columns:   \n",
    "    df_trip_id = df_trip_id.merge(links[['trip_id', 'route_id', 'route_type', 'capacity', 'headway', 'headway_ph', 'headway_oph', 'nb_peak_hours']], on='trip_id', how='left')\n",
    "else:\n",
    "    df_trip_id = df_trip_id.merge(links[['trip_id', 'route_id', 'route_type', 'capacity', 'headway']], on='trip_id', how='left')\n",
    "df_trip_id = df_trip_id.rename(columns={'capacity': 'veh_capacity (PAX)'})\n",
    "df_trip_id = df_trip_id.drop_duplicates()\n",
    "df_trip_id = df_trip_id.set_index('trip_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "dbac81bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_route_type = pd.DataFrame(index=links['route_type'].unique())\n",
    "df_route_type.index.name='route_type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "f5cc4bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure headways are consistent : one single headway for both way and return\n",
    "# Otherwise can't calculate KPIs later\n",
    "\n",
    "df_route_id = df_route_id[~df_route_id.index.duplicated(keep='first')]\n",
    "route_headway = dict(zip(df_route_id.index, df_route_id['headway']))\n",
    "links.headway = links.route_id.map(route_headway)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8fb983",
   "metadata": {},
   "source": [
    "# Catchment calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "2d54b3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_catchment_by_mode(col='route_id', pop_col='population', node_dist=None):\n",
    "    #get all nodes with col filter\n",
    "    link = links.groupby(col)[['a','b','route_type', 'catchment_radius']].agg({'a':set,'b':set,'route_type':'first', 'catchment_radius': 'first'})\n",
    "    link['node'] = link.apply(lambda row: row['a'].union(row['b']), axis=1)\n",
    "    link = link.drop(columns=['a','b'])\n",
    "\n",
    "    col_exist = col == 'route_type' # cannot explode if index == route_type (a column)\n",
    "    link = link.explode('node').reset_index(drop=col_exist)\n",
    "    link = node_dist.merge(link, left_on='node_index', right_on='node')\n",
    "    #filter by distance\n",
    "    link = link[link['distances'] <= link['catchment_radius']]\n",
    "    #drop duplicated mesh nodes (we count only one time)\n",
    "    link = link.drop_duplicates(subset=['mesh_index',col],keep='first')\n",
    "\n",
    "    return link.groupby(col)[pop_col].sum().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "8b150d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_catchment_by_access(col='route_id', pop_col='population', catchment_col='catchment_radius', node_dist=None):\n",
    "    #get all nodes with col filter\n",
    "    link = links.groupby(col)[['a','b','route_type', catchment_col]].agg({'a':set,'b':set,'route_type':'first', catchment_col:'first'})\n",
    "    link['node'] = link.apply(lambda row: row['a'].union(row['b']), axis=1)\n",
    "    link = link.drop(columns=['a','b'])\n",
    "\n",
    "    col_exist = col == 'route_type' # cannot explode if index == route_type (a column)\n",
    "    link = link.explode('node').reset_index(drop=col_exist)\n",
    "    link = node_dist.merge(link, left_on='node_index', right_on='node')\n",
    "    #filter by distance\n",
    "    link = link[link['distances'] <= link[catchment_col]]\n",
    "    #drop duplicated mesh nodes (we count only one time)\n",
    "    link = link.drop_duplicates(subset=['mesh_index',col],keep='first')\n",
    "\n",
    "    return link.groupby(col)[pop_col].sum().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "c438144c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "population\n",
      "using road_nodes\n",
      "0 nodes in multiple zones. will be match to a single zone.\n",
      "13 unfounded zones\n",
      "using road_nodes\n"
     ]
    }
   ],
   "source": [
    "meshes = {}\n",
    "## road network here\n",
    "for density in densities:\n",
    "    if density == 'density' and 'population_density' not in densities:\n",
    "        tag = 'population'\n",
    "    elif density == 'density':\n",
    "        tag = 'x'\n",
    "    else:\n",
    "        tag = density.split('_density')[0]\n",
    "\n",
    "    print(tag)\n",
    "\n",
    "    zonage[tag] = zonage[density] * zonage['area (km2)']\n",
    "\n",
    "    if rnodes_file_provided and use_road_network:\n",
    "        # use rnodes as mesh_pop.\n",
    "        print('using road_nodes') ## road network here\n",
    "        mesh = population_to_mesh(zonage, mesh=rnodes, step=step_size, col=tag, fill_missing='closest')\n",
    "    else:\n",
    "        # create a mesh\n",
    "        mesh = population_to_mesh(zonage, mesh=None, step=step_size, col=tag, fill_missing='centroid')\n",
    "\n",
    "    #mesh.to_file(output_folder + 'population_mesh.geojson',driver='GeoJSON',engine=io_engine)\n",
    "    if catchment_radii_provided:\n",
    "        max_dist = max([links[catchment_radius].max() for catchment_radius in catchment_radii])\n",
    "    else:\n",
    "        # max_dist = max(max(input_catchment_radius.values()),default_catchment_radius)\n",
    "        max_dist = default_catchment_radius\n",
    "\n",
    "    ## road network here, what to use if not road network?\n",
    "    if rnodes_file_provided: \n",
    "        print('using road_nodes')\n",
    "        node_dist = get_routing_distances(nodes, rnodes, rlinks, mesh, tag, 'length', max_dist)\n",
    "    else:\n",
    "        node_dist = get_acf_distances(nodes, mesh, tag, crs, max_dist)\n",
    "\n",
    "    if catchment_radii_provided:\n",
    "        for catchment_radius in catchment_radii:\n",
    "            suf = catchment_radius.split('catchment_radius_')[1]\n",
    "\n",
    "            res_trip = get_catchment_by_access('trip_id', tag, catchment_radius, node_dist)\n",
    "            res_route = get_catchment_by_access('route_id', tag, catchment_radius, node_dist)\n",
    "            res_mode = get_catchment_by_access('route_type', tag, catchment_radius, node_dist)\n",
    "\n",
    "            if suf == '':\n",
    "                df_trip_id['catchment {}'.format(tag)] = res_trip\n",
    "                df_trip_id['catchment {}'.format(tag)] = df_trip_id['catchment {}'.format(tag)].fillna(0) \n",
    "\n",
    "                df_route_id['catchment {}'.format(tag)] = res_route\n",
    "                df_route_id['catchment {}'.format(tag)] = df_route_id['catchment {}'.format(tag)].fillna(0) \n",
    "\n",
    "                df_route_type['catchment {}'.format(tag)] = res_mode\n",
    "                df_route_type['catchment {}'.format(tag)] = df_route_type['catchment {}'.format(tag)].fillna(0) \n",
    "\n",
    "            else:\n",
    "                df_trip_id['catchment {} {}'.format(tag, suf)] = res_trip\n",
    "                df_trip_id['catchment {} {}'.format(tag, suf)] = df_trip_id['catchment {} {}'.format(tag, suf)].fillna(0) \n",
    "\n",
    "                df_route_id['catchment {} {}'.format(tag, suf)] = res_route\n",
    "                df_route_id['catchment {} {}'.format(tag, suf)] = df_route_id['catchment {} {}'.format(tag, suf)].fillna(0) \n",
    "\n",
    "                df_route_type['catchment {} {}'.format(tag, suf)] = res_mode\n",
    "                df_route_type['catchment {} {}'.format(tag, suf)] = df_route_type['catchment {} {}'.format(tag, suf)].fillna(0) \n",
    "\n",
    "    else:\n",
    "        res_trip = get_catchment_by_mode('trip_id', tag, node_dist)\n",
    "        res_route = get_catchment_by_mode('route_id', tag, node_dist)\n",
    "        res_mode = get_catchment_by_mode('route_type', tag, node_dist)\n",
    "\n",
    "        df_trip_id['catchment {}'.format(tag)] = res_trip\n",
    "        df_trip_id['catchment {}'.format(tag)] = df_trip_id['catchment {}'.format(tag)].fillna(0) \n",
    "\n",
    "        df_route_id['catchment {}'.format(tag)] = res_route\n",
    "        df_route_id['catchment {}'.format(tag)] = df_route_id['catchment {}'.format(tag)].fillna(0) \n",
    "\n",
    "        df_route_type['catchment {}'.format(tag)] = res_mode\n",
    "        df_route_type['catchment {}'.format(tag)] = df_route_type['catchment {}'.format(tag)].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5d12fd",
   "metadata": {},
   "source": [
    "# Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "950bfa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Suppose that headway is not the same in both directions : keep the minimum value\n",
    "# idx = df_route_id.groupby(level=0)['headway'].idxmin()\n",
    "# df_route_id = df_route_id.loc[idx]\n",
    "\n",
    "# df_route_id = df_route_id.rename(columns={'headway': 'headway (s)'})\n",
    "# df_route_id = df_route_id.sort_values('route_type', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "3f251696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# links['frequency'] = 1/links['headway']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "3829349f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = (links.groupby('route_id')['frequency'].agg('mean')*3600).to_dict()\n",
    "\n",
    "# df_route_id['frequency (veh/hours)'] = res\n",
    "# print(np.nansum([item for key, item in res.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "e3035415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = (links.groupby('route_type')['frequency'].agg('mean')*3600).to_dict()\n",
    "\n",
    "# df_route_type['frequency (veh/hours)'] = res\n",
    "# print(sum([item for key, item in res.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "c661a29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'departures' in links.columns:\n",
    "    links['link_has_timetable'] = links['departures'].apply(lambda x: 0 if x is None else 1)\n",
    "    lines_with_timetable = links.groupby('route_id')['link_has_timetable'].min()\n",
    "    links['line_has_timetable'] = links['route_id'].map(lines_with_timetable)\n",
    "    links.drop(columns='link_has_timetable', inplace=True)\n",
    "else:\n",
    "    links['line_has_timetable'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "4f15f321",
   "metadata": {},
   "outputs": [],
   "source": [
    "default = {'headway_ph': links['headway'].max(),\n",
    "           'headway_oph': links['headway'].max(),\n",
    "           'nb_service_hours': 14,\n",
    "           'nb_peak_hours': 14}\n",
    "\n",
    "dic_headway = links.groupby('route_id')['headway'].min()\n",
    "\n",
    "for col in ['headway_ph', 'headway_oph']:\n",
    "    if col not in links.columns:\n",
    "        links[col] = default[col]\n",
    "    else: \n",
    "        dic_col = links.groupby('route_id')[col].min()\n",
    "        links[col] = links['route_id'].map(dic_col)\n",
    "        links.loc[links[col].isna(), col] = links.loc[links[col].isna(), 'route_id'].map(dic_headway)\n",
    "        links[col] = links[col].astype(int)\n",
    "\n",
    "for col in ['nb_service_hours', 'nb_peak_hours']:\n",
    "    if col not in links.columns:\n",
    "        links[col] = default[col]\n",
    "    else:\n",
    "        links[col] = links[col]\n",
    "        dic_col = links.groupby('route_id')[col].max()\n",
    "        links[col] = links['route_id'].map(dic_col).fillna(default[col])\n",
    "        links[col] = links[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "f8db3069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def time_seconds(time_str):\n",
    "    time_obj = datetime.strptime(time_str, '%H:%M:%S')\n",
    "    return time_obj.hour * 3600 + time_obj.minute * 60 + time_obj.second\n",
    "\n",
    "def retrieve_avg_headway(departures):\n",
    "    deps_seconds = [time_seconds(t) for t in departures]\n",
    "    if len(deps_seconds) >= 1:\n",
    "        gaps = [deps_seconds[i] - deps_seconds[i-1] for i in range(1, len(deps_seconds))]\n",
    "        return int(np.average(gaps))\n",
    "    return None\n",
    "\n",
    "def retrieve_oph_headway(departures):\n",
    "    deps_seconds = [time_seconds(t) for t in departures]\n",
    "    if len(deps_seconds) >= 1:\n",
    "        gaps = [deps_seconds[i] - deps_seconds[i-1] for i in range(1, len(deps_seconds))]\n",
    "        return max(gaps)\n",
    "    return None\n",
    "\n",
    "def retrieve_ph_headway(departures):\n",
    "    deps_seconds = [time_seconds(t) for t in departures]\n",
    "    if len(deps_seconds) >= 1:\n",
    "        gaps = [deps_seconds[i] - deps_seconds[i-1] for i in range(1, len(deps_seconds))]\n",
    "        return min(gaps)\n",
    "    return None\n",
    "\n",
    "def retrieve_service_hours(departures):\n",
    "    deps_seconds = [time_seconds(t) for t in departures]\n",
    "    if len(deps_seconds) >= 1:\n",
    "        return (deps_seconds[-1] - deps_seconds[0])/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "81e40ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "links.loc[links['line_has_timetable'] == 1, 'frequency_per_day'] = links.loc[links['line_has_timetable'] == 1].apply(lambda x: len(x['departures']), 1)\n",
    "links.loc[links['line_has_timetable'] == 0, 'frequency_per_day'] = links.loc[links['line_has_timetable'] == 0].apply(lambda x: np.ceil(3600*(x['nb_peak_hours']/x['headway_ph'] + (x['nb_service_hours'] - x['nb_peak_hours'])/x['headway_oph'])), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "ba168d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "links.loc[links['line_has_timetable']==1, 'headway'] = links.loc[links['line_has_timetable']==1, 'departures'].apply(retrieve_avg_headway)\n",
    "links.loc[links['line_has_timetable']==1, 'headway_ph'] = links.loc[links['line_has_timetable']==1, 'departures'].apply(retrieve_ph_headway)\n",
    "links.loc[links['line_has_timetable']==1, 'headway_oph'] = links.loc[links['line_has_timetable']==1, 'departures'].apply(retrieve_oph_headway)\n",
    "links.loc[links['line_has_timetable']==1, 'nb_service_hours'] = links.loc[links['line_has_timetable']==1, 'departures'].apply(retrieve_service_hours)\n",
    "links.loc[links['line_has_timetable']==1, 'nb_peak_hours'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "9e84f1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "links['frequency (veh/hour)'] = 1/links['headway']*3600\n",
    "links['frequency ph (veh/hour)'] = 1/links['headway_ph']*3600\n",
    "links['frequency oph (veh/hour)'] = 1/links['headway_oph']*3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "b7a34049",
   "metadata": {},
   "outputs": [],
   "source": [
    "links['headway'] = links.apply(lambda x: x['headway'] if (x['headway_ph'] == x['headway_oph']) else None, 1)\n",
    "links['frequency (veh/hour)'] = links.apply(lambda x: x['frequency (veh/hour)'] if (x['frequency ph (veh/hour)'] == x['frequency oph (veh/hour)']) else None, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "3d8badd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_hour = (links.groupby('route_id')['frequency (veh/hour)'].agg('mean')).to_dict()\n",
    "res_day = (links.groupby('route_id')['frequency_per_day'].agg('mean')).to_dict()\n",
    "\n",
    "df_route_id['frequency (veh/day)'] = res_day\n",
    "df_route_id['frequency (veh/hour)'] = res_hour\n",
    "\n",
    "if display_ph_columns:\n",
    "    res_ph = (links.loc[links['frequency ph (veh/hour)'] != links['frequency oph (veh/hour)']].groupby('route_id')['frequency ph (veh/hour)'].agg('mean')*3600).to_dict()\n",
    "    res_oph = (links.loc[links['frequency ph (veh/hour)'] != links['frequency oph (veh/hour)']].groupby('route_id')['frequency oph (veh/hour)'].agg('mean')*3600).to_dict()\n",
    "\n",
    "    df_route_id['frequency ph (veh/hour)'] = res_ph\n",
    "    df_route_id['frequency oph (veh/hour)'] = res_oph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "09422553",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_hour = (links.groupby('trip_id')['frequency (veh/hour)'].agg('mean')).to_dict()\n",
    "res_day = (links.groupby('trip_id')['frequency_per_day'].agg('mean')).to_dict()\n",
    "\n",
    "df_trip_id['frequency (veh/day)'] = res_day\n",
    "df_trip_id['frequency (veh/hour)'] = res_hour\n",
    "\n",
    "if display_ph_columns:\n",
    "    res_ph = (links.loc[links['frequency ph (veh/hour)'] != links['frequency oph (veh/hour)']].groupby('trip_id')['frequency ph (veh/hour)'].agg('mean')*3600).to_dict()\n",
    "    res_oph = (links.loc[links['frequency ph (veh/hour)'] != links['frequency oph (veh/hour)']].groupby('trip_id')['frequency oph (veh/hour)'].agg('mean')*3600).to_dict()\n",
    "\n",
    "    df_trip_id['frequency ph (veh/hour)'] = res_ph\n",
    "    df_trip_id['frequency oph (veh/hour)'] = res_oph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "44a662c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_hour = (links.groupby('route_type')['frequency (veh/hour)'].agg('mean')).to_dict()\n",
    "res_day = (links.groupby('route_type')['frequency_per_day'].agg('mean')).to_dict()\n",
    "\n",
    "df_route_type['frequency (veh/day)'] = res_day\n",
    "df_route_type['frequency (veh/hour)'] = res_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a16eb3",
   "metadata": {},
   "source": [
    "# Line Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "e3273ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length(col='route_id', length_col='length'):\n",
    "    link = links.groupby([col,'trip_id'])[[length_col]].agg(np.nansum)\n",
    "    if col == 'route_type':\n",
    "        return link.reset_index().groupby(col)[length_col].agg(np.nansum).to_dict()\n",
    "    else:\n",
    "        return link.reset_index().groupby(col)[length_col].agg(np.nanmean).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "bfa2e75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparation. if length is NaN, or if shape dist travel exist.\n",
    "\n",
    "length_col = None\n",
    "if 'length' in links.columns and length_col == None:\n",
    "    if len(links[links['length'].isnull()])==0:\n",
    "        length_col = 'length'\n",
    "        \n",
    "if 'shape_dist_traveled' in links.columns and length_col == None:\n",
    "    if len(links[links['shape_dist_traveled'].isnull()])==0:\n",
    "        length_col = 'shape_dist_traveled'\n",
    "\n",
    "if length_col == None:\n",
    "    print('create length from geometry')\n",
    "    links['length'] = links.to_crs(crs).length\n",
    "    length_col = 'length'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "31db0758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80760.0\n"
     ]
    }
   ],
   "source": [
    "res = get_length('route_id',length_col)\n",
    "\n",
    "df_route_id['length (m)'] = res\n",
    "print(sum([item for key,item in res.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "39826011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161520\n"
     ]
    }
   ],
   "source": [
    "res = get_length('route_type',length_col)\n",
    "\n",
    "df_route_type['length (m)'] = res\n",
    "print(sum([item for key,item in res.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638013ee",
   "metadata": {},
   "source": [
    "# Number of station per line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "6bf1bd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# o-->o-->o-->o and  o<--o<--o<--o\n",
    "# est-ce que j'ai 8 ou 4 stations ?\n",
    "# j'ai 4 stations par trip et 4 stations par route (si c'est les memes).\n",
    "# comment savoir si cest les mêmes : clustering?\n",
    "# pour l'instant on prend tous les noeuds unique par route_id ou route_type (col='route_id', route_id)\n",
    "def get_num_station(col='route_id'):\n",
    "    link = links.groupby(col)[['a','b']].agg({'a':set,'b':set})\n",
    "    link['node_len'] = link.apply(lambda row: len(row['a'].union(row['b'])), axis=1)\n",
    "    return link['node_len'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "53a9fb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!! Duplicates in node names !!\n"
     ]
    }
   ],
   "source": [
    "nodes['nindex'] = nodes.reset_index().index\n",
    "nodes['stop_name'] = nodes.apply(lambda x: x['nindex'] if (pd.isna(x['stop_name']) or x['stop_name'] is None) else x['stop_name'], 1)\n",
    "nodes.drop(columns='nindex', inplace=True)\n",
    "\n",
    "links['a_name'] = links['a'].map(nodes['stop_name'].to_dict())\n",
    "links['b_name'] = links['b'].map(nodes['stop_name'].to_dict())\n",
    "\n",
    "if len(nodes['stop_name'].values.tolist()) > len(nodes['stop_name'].unique()):\n",
    "    print('!! Duplicates in node names !!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "0eebf302",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_nb_trips = links[['route_id', 'trip_id']].drop_duplicates().groupby('route_id')['trip_id'].count().to_dict()\n",
    "df_route_id['type'] = df_route_id.index.map(dict_nb_trips)\n",
    "df_route_id['type'] = df_route_id['type'].apply(lambda x: 'circular' if x == 1 else 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "2165039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_sequence(route_id):\n",
    "    links_route = links.loc[links.route_id == route_id]\n",
    "    if df_route_id.loc[route_id]['type'] == 'linear':\n",
    "        trip_id = route_id + '_0'\n",
    "    links_route = links_route.loc[links_route.trip_id == trip_id]\n",
    "    links_route = links_route.sort_values(by='link_sequence')\n",
    "    nodes_seq = []\n",
    "    for i in range(len(links_route)):\n",
    "        nodes_seq += [links_route.iloc[i]['a']]\n",
    "    nodes_seq += [links_route.iloc[-1]['b']]\n",
    "    return nodes_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "f19ccc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_stops = dict(zip(nodes.index, nodes['stop_name']))\n",
    "\n",
    "def get_stops_sequence(route_id):\n",
    "    nodes_seq = get_node_sequence(route_id)\n",
    "    stops_seq = []\n",
    "    for node in nodes_seq:\n",
    "        stops_seq += [nodes_stops[node]]\n",
    "    return stops_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "b44ac2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_route_id['stations sequence'] = [get_stops_sequence(route_id) for route_id in df_route_id.index]\n",
    "df_route_id['nodes sequence'] = [get_node_sequence(route_id) for route_id in df_route_id.index]\n",
    "df_route_id['nb stations'] = df_route_id['stations sequence'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "ffa6009d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_route_type = pd.DataFrame(df_route_id.groupby('route_type')['stations sequence'].agg(lambda x: list(set(sum(x, [])))))\n",
    "stations_route_type['nb stations'] = stations_route_type['stations sequence'].apply(lambda x: len(x))\n",
    "df_route_type = df_route_type.merge(stations_route_type, left_on=df_route_type.index, right_on=stations_route_type.index, how='left')\n",
    "df_route_type = df_route_type.rename(columns={'key_0': 'route_type'})\n",
    "df_route_type = df_route_type.set_index('route_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1ea85a",
   "metadata": {},
   "source": [
    "## Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "5549961a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterable = list(zip(nodes['stop_name'], nodes.index))\n",
    "\n",
    "stops_nodes = defaultdict(set)\n",
    "for key, value in iterable:\n",
    "    stops_nodes[key].add(value)\n",
    "stops_nodes = dict(stops_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "2cacdef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterable = list(zip(links['a'], links['route_id']))\n",
    "iterable = iterable + list(zip(links['b'], links['route_id']))\n",
    "\n",
    "nodes_routes = defaultdict(set)\n",
    "for key, value in iterable:\n",
    "    nodes_routes[key].add(value)\n",
    "nodes_routes = dict(nodes_routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "d314d997",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_routes = {}\n",
    "\n",
    "for stop, node_list in stops_nodes.items():\n",
    "    routes = set()\n",
    "    for node in node_list:\n",
    "        if node in nodes_routes:\n",
    "            routes.update(nodes_routes[node])\n",
    "    stops_routes[stop] = routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "074016b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hubs = pd.DataFrame.from_dict(stops_routes, orient='index')\n",
    "hubs['lines'] = hubs.apply(lambda row: [val for val in row if pd.notnull(val)], axis=1)\n",
    "hubs = hubs.drop(columns=[i for i in range(len(hubs.columns) - 1)])\n",
    "hubs['nb_lines'] = hubs['lines'].apply(lambda x: len(x))\n",
    "hubs = hubs.sort_values(by='nb_lines', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "b639caa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_route_type = dict(zip(df_route_id.index, df_route_id['route_type']))\n",
    "dict_veh = dict(zip(df_route_id['route_type'], df_route_id['veh_capacity (PAX)']))\n",
    "route_order = sorted(dict_veh, key=lambda x: int(dict_veh[x]), reverse=True)\n",
    "\n",
    "def lines_to_dict(lines):\n",
    "    route_dict = {route_type: [] for route_type in route_order}\n",
    "    for line in lines:\n",
    "        route_type = dict_route_type.get(line)\n",
    "        if route_type in route_dict:\n",
    "            route_dict[route_type].append(line)\n",
    "    route_dict = {k: sorted(v) for k, v in route_dict.items() if v}\n",
    "    return route_dict\n",
    "\n",
    "hubs['lines'] = hubs['lines'].apply(lines_to_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "792c180d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.ops import unary_union\n",
    "\n",
    "def centroid(geometries):\n",
    "    combined_geometry = unary_union(geometries)\n",
    "    return combined_geometry.centroid\n",
    "\n",
    "centroids = pd.DataFrame(nodes.groupby('stop_name')['geometry'].agg(centroid))\n",
    "hubs = hubs.merge(centroids, left_on=hubs.index, right_on=centroids.index, how='left')\n",
    "\n",
    "hubs = hubs.rename(columns={'key_0': 'stop_name'})\n",
    "hubs = hubs.set_index('stop_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "feed3cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hubs['stop_radius'] = hubs['lines'].apply(lambda x: max(catchment_radius[mode] for mode in x.keys()))\n",
    "hubs['stop_radius'] = default_catchment_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "ac08444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_connections(row):\n",
    "    route_id = row.name\n",
    "    connections = set()\n",
    "    for station in row['stations sequence']:\n",
    "        if station in stops_routes:\n",
    "            connections.update(stops_routes[station])\n",
    "    connections.discard(route_id)  # Supprimer la route_id de l'ensemble des connexions\n",
    "    return lines_to_dict(connections), len(connections)\n",
    "\n",
    "df_route_id[['connexions', 'nb lines connected']] = df_route_id.apply(lambda row: pd.Series(get_connections(row)), axis=1)\n",
    "\n",
    "# df_route_id[['connexions']].loc[df_route_id['connexions'] == 'tertiary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "ecfae70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_route_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7f7371",
   "metadata": {},
   "source": [
    "# Operational Fleet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "7062adf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_fleet(col='route_id'):\n",
    "#     link = links.groupby([col,'trip_id'])[['time', 'frequency']].agg({'time': np.nansum, 'frequency': np.nanmean})\n",
    "#     link['fleet'] = np.ceil(link['frequency'] * (link['time'] + 300))\n",
    "#     return link.reset_index().groupby(col)['fleet'].agg(np.nansum).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "7c33dfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = get_fleet('route_id')\n",
    "\n",
    "# #df_route_id['fleet'] = res\n",
    "# #print(sum([item for key,item in res.items()]))\n",
    "# res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "6e408e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fleet_frequency(route_id):\n",
    "    link = links.loc[links['route_id'] == route_id].groupby(['route_id','trip_id'])[['time','frequency']].agg({'time': np.nansum,'frequency': 'mean'})\n",
    "    link['fleet'] = np.ceil(link['frequency'] * link['time'])\n",
    "    return link['fleet'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "c485b13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fleet_timetable(route_id):\n",
    "    link = links.loc[links['route_id'] == route_id]\n",
    "    stations_sequence = df_route_id.loc[route_id]['nodes sequence']\n",
    "    circular_line = df_route_id.loc[route_id]['type'] == 'circular'\n",
    "\n",
    "    termini = [stations_sequence[0], stations_sequence[-1]]\n",
    "    link['a_terminus'] = link['a'].isin(termini)\n",
    "    link['b_terminus'] = link['b'].isin(termini)\n",
    "\n",
    "    if not circular_line:\n",
    "        dep0_times = link.loc[(link['trip_id'] == route_id + '_0') & link['a_terminus']]['departures'].values.tolist()[0]\n",
    "        dep1_times = link.loc[(link['trip_id'] == route_id + '_1') & link['a_terminus']]['departures'].values.tolist()[0]\n",
    "        arr0_times = link.loc[(link['trip_id'] == route_id + '_0') & link['b_terminus']]['arrivals'].values.tolist()[0]\n",
    "        arr1_times = link.loc[(link['trip_id'] == route_id + '_1') & link['b_terminus']]['arrivals'].values.tolist()[0]\n",
    "\n",
    "        dep0 = [time_seconds(t) for t in dep0_times]\n",
    "        dep1 = [time_seconds(t) for t in dep1_times]\n",
    "        arr0 = [time_seconds(t) for t in arr0_times]\n",
    "        arr1 = [time_seconds(t) for t in arr1_times]\n",
    "\n",
    "        travel_time0 = arr0[0] - dep0[0]\n",
    "        travel_time1 = arr1[0] - dep1[0]\n",
    "\n",
    "        nb_interbuses = []\n",
    "\n",
    "        for bus in dep0:\n",
    "            departure = bus\n",
    "            arrival = departure + travel_time0\n",
    "            if arrival < max(dep1):\n",
    "                departure_ = min([dep for dep in dep1 if dep>arrival])\n",
    "                tmax = departure_ + travel_time1\n",
    "            else:\n",
    "                tmax = max([max(dep0), max(arr1)])\n",
    "\n",
    "            t = bus\n",
    "            necessary_buses = 1\n",
    "            reserve_buses = 0\n",
    "            departures = [dep for dep in dep0 if dep>t]\n",
    "            arrivals = [arr for arr in arr1 if arr>t]\n",
    "\n",
    "            while t < tmax:\n",
    "                try:\n",
    "                    next_event = min([min(departures), min(arrivals)])\n",
    "                except ValueError:\n",
    "                    break\n",
    "                t=next_event\n",
    "                if (next_event in departures) and (next_event in arrivals):\n",
    "                    departures.pop(0)\n",
    "                    arrivals.pop(0)\n",
    "                    pass\n",
    "                elif next_event in departures:\n",
    "                    departures.pop(0)\n",
    "                    if reserve_buses >= 1:\n",
    "                        reserve_buses -= 1\n",
    "                    else:\n",
    "                        necessary_buses += 1\n",
    "                elif next_event in arrivals:\n",
    "                    arrivals.pop(0)\n",
    "                    necessary_buses += 1\n",
    "                    reserve_buses += 1\n",
    "\n",
    "            nb_interbuses.append(necessary_buses)\n",
    "\n",
    "        for bus in dep1:\n",
    "            departure = bus\n",
    "            arrival = departure + travel_time1\n",
    "            if arrival < max(dep0):\n",
    "                departure_ = min([dep for dep in dep0 if dep>arrival])\n",
    "                tmax = departure_ + travel_time0\n",
    "            else:\n",
    "                tmax = max([max(dep1), max(arr0)])\n",
    "\n",
    "            t = bus\n",
    "            necessary_buses = 1\n",
    "            reserve_buses = 0\n",
    "            departures = [dep for dep in dep1 if dep>t]\n",
    "            arrivals = [arr for arr in arr0 if arr>t]\n",
    "\n",
    "            while t < tmax:\n",
    "                try:\n",
    "                    next_event = min([min(departures), min(arrivals)])\n",
    "                except ValueError:\n",
    "                    break\n",
    "                t=next_event\n",
    "                if (next_event in departures) and (next_event in arrivals):\n",
    "                    departures.pop(0)\n",
    "                    arrivals.pop(0)\n",
    "                    pass\n",
    "                elif next_event in departures:\n",
    "                    departures.pop(0)\n",
    "                    if reserve_buses >= 1:\n",
    "                        reserve_buses -= 1\n",
    "                    else:\n",
    "                        necessary_buses += 1\n",
    "                elif next_event in arrivals:\n",
    "                    arrivals.pop(0)\n",
    "                    necessary_buses += 1\n",
    "                    reserve_buses += 1\n",
    "\n",
    "            nb_interbuses.append(necessary_buses)\n",
    "    \n",
    "    else:\n",
    "        dep0_times = link.loc[(link['trip_id'] == route_id + '_0') & link['a_terminus']]['departures'].values.tolist()[0]\n",
    "        arr0_times = link.loc[(link['trip_id'] == route_id + '_0') & link['b_terminus']]['arrivals'].values.tolist()[0]\n",
    "\n",
    "        dep0 = [time_seconds(t) for t in dep0_times]\n",
    "        arr0 = [time_seconds(t) for t in arr0_times]\n",
    "\n",
    "        travel_time0 = arr0[0] - dep0[0]\n",
    "\n",
    "        nb_interbuses = []\n",
    "        for bus in dep0:\n",
    "            departure = bus\n",
    "            arrival = departure + travel_time0\n",
    "            n_buses = len([dep for dep in dep0 if (dep>=bus and dep<arrival)])\n",
    "            nb_interbuses.append(n_buses)\n",
    "\n",
    "    return max(max(nb_interbuses), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "e79fd723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_service_hours_timetable(route_id):\n",
    "    link = links.loc[links['route_id'] == route_id]\n",
    "    stations_sequence = df_route_id.loc[route_id]['nodes sequence']\n",
    "    circular_line = df_route_id.loc[route_id]['type'] == 'circular'\n",
    "\n",
    "    termini = [stations_sequence[0], stations_sequence[-1]]\n",
    "    link['a_terminus'] = link['a'].isin(termini)\n",
    "    link['b_terminus'] = link['b'].isin(termini)\n",
    "\n",
    "    if not circular_line:\n",
    "        dep0_times = link.loc[(link['trip_id'] == route_id + '_0') & link['a_terminus']]['departures'].values.tolist()[0]\n",
    "        dep1_times = link.loc[(link['trip_id'] == route_id + '_1') & link['a_terminus']]['departures'].values.tolist()[0]\n",
    "        arr0_times = link.loc[(link['trip_id'] == route_id + '_0') & link['b_terminus']]['arrivals'].values.tolist()[0]\n",
    "        arr1_times = link.loc[(link['trip_id'] == route_id + '_1') & link['b_terminus']]['arrivals'].values.tolist()[0]\n",
    "\n",
    "        dep0 = [time_seconds(t) for t in dep0_times]\n",
    "        dep1 = [time_seconds(t) for t in dep1_times]\n",
    "        arr0 = [time_seconds(t) for t in arr0_times]\n",
    "        arr1 = [time_seconds(t) for t in arr1_times]\n",
    "\n",
    "        time_range = np.ceil((max([max(arr0), max(arr1)]) - min([min(dep0), min(dep1)]))/3600)\n",
    "\n",
    "    return time_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "720618f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "links.loc[links['line_has_timetable']==1, 'fleet'] = links.loc[links['line_has_timetable']==1, 'route_id'].apply(get_fleet_timetable)\n",
    "links.loc[links['line_has_timetable']==1, 'nb_service_hours'] = links.loc[links['line_has_timetable']==1, 'route_id'].apply(get_service_hours_timetable)\n",
    "\n",
    "links.loc[links['line_has_timetable']==0, 'fleet'] = links.loc[links['line_has_timetable']==0, 'route_id'].apply(get_fleet_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "9edaf727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 12, 12, 14, 14, 14, 14, 12, 12, 14]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links['nb_service_hours'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "723df21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (links.groupby('trip_id')['nb_service_hours'].agg('mean')).to_dict()\n",
    "df_trip_id['nb_service_hours'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "7747777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (links.groupby('route_id')['fleet'].agg('mean')).to_dict()\n",
    "df_route_id['fleet'] = res\n",
    "\n",
    "res = (links.groupby('route_id')['nb_service_hours'].agg('mean')).to_dict()\n",
    "df_route_id['nb_service_hours'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "f4af8692",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = df_route_id.reset_index().groupby('route_type')['fleet'].agg('sum').to_dict()\n",
    "df_route_type['fleet'] = res\n",
    "\n",
    "res = df_route_id.reset_index().groupby('route_type')['nb_service_hours'].agg('max').to_dict()\n",
    "df_route_type['nb_service_hours'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "600beb1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>b</th>\n",
       "      <th>nb_peak_hours</th>\n",
       "      <th>headway_oph</th>\n",
       "      <th>route_id</th>\n",
       "      <th>route_short_name</th>\n",
       "      <th>pickup_type</th>\n",
       "      <th>a</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>time</th>\n",
       "      <th>...</th>\n",
       "      <th>capex</th>\n",
       "      <th>catchment_radius</th>\n",
       "      <th>line_has_timetable</th>\n",
       "      <th>frequency_per_day</th>\n",
       "      <th>frequency (veh/hour)</th>\n",
       "      <th>frequency ph (veh/hour)</th>\n",
       "      <th>frequency oph (veh/hour)</th>\n",
       "      <th>a_name</th>\n",
       "      <th>b_name</th>\n",
       "      <th>fleet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>link_qTNjaUDLm9x3yJrS9ubX9T</th>\n",
       "      <td>LINESTRING (3.2042 46.0974, 3.20418 46.09764, ...</td>\n",
       "      <td>node_6CErzt5T6gFonN6RkpvAM6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>700</td>\n",
       "      <td>Gannat</td>\n",
       "      <td>Gannat</td>\n",
       "      <td>0</td>\n",
       "      <td>node_2zTroDrJuDCKmipdvjBrtL</td>\n",
       "      <td>Gannat_0</td>\n",
       "      <td>3295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.2</td>\n",
       "      <td>5.142857</td>\n",
       "      <td>Gannat</td>\n",
       "      <td>Vichy</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>link_wvPcELKEW52njEnuK7AeSe</th>\n",
       "      <td>LINESTRING (3.06 45.92018, 3.0606 45.92013, 3....</td>\n",
       "      <td>node_b8e2FB6qm9PUQTLvQvNucR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7200</td>\n",
       "      <td>ChatelGuyon</td>\n",
       "      <td>ChatelGuyon</td>\n",
       "      <td>0</td>\n",
       "      <td>node_f8Fb3oREhTRCmTVNW7TQzE</td>\n",
       "      <td>ChatelGuyon_0</td>\n",
       "      <td>1175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Chatel Guyon</td>\n",
       "      <td>Riom</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>link_vTbX3V9qJJxThakJ1WZbbk</th>\n",
       "      <td>LINESTRING (3.07285 45.8958, 3.07269 45.89586,...</td>\n",
       "      <td>node_wbHMs2n7zPVS1pp1cXnNw5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7200</td>\n",
       "      <td>ChatelGuyon</td>\n",
       "      <td>ChatelGuyon</td>\n",
       "      <td>0</td>\n",
       "      <td>node_b8e2FB6qm9PUQTLvQvNucR</td>\n",
       "      <td>ChatelGuyon_0</td>\n",
       "      <td>2980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Riom</td>\n",
       "      <td>Clermont</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>link_8EachMgBpjP7T2bWPiAc3E</th>\n",
       "      <td>LINESTRING (3.50444 45.85987, 3.50422 45.85993...</td>\n",
       "      <td>node_a3ZLvXzFnMqGNGu4hjEYT6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>600</td>\n",
       "      <td>Thiers</td>\n",
       "      <td>Thiers</td>\n",
       "      <td>0</td>\n",
       "      <td>node_4b2VnuC1zTsPzd9ueovVuH</td>\n",
       "      <td>Thiers_0</td>\n",
       "      <td>2344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>Thiers</td>\n",
       "      <td>Ornon</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>link_purLhqauca5SLLCFkShEC7</th>\n",
       "      <td>LINESTRING (3.38307 45.84869, 3.38239 45.84873...</td>\n",
       "      <td>node_rwwVbaGFJtCHoKTZ6B83Ax</td>\n",
       "      <td>14.0</td>\n",
       "      <td>600</td>\n",
       "      <td>Thiers</td>\n",
       "      <td>Thiers</td>\n",
       "      <td>0</td>\n",
       "      <td>node_a3ZLvXzFnMqGNGu4hjEYT6</td>\n",
       "      <td>Thiers_0</td>\n",
       "      <td>4744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>Ornon</td>\n",
       "      <td>Clermont</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>link_4hsYkThjafc1NVpc8kLeid</th>\n",
       "      <td>LINESTRING (3.0996 45.77888, 3.0994 45.77877, ...</td>\n",
       "      <td>node_a3ZLvXzFnMqGNGu4hjEYT6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>600</td>\n",
       "      <td>Thiers</td>\n",
       "      <td>Thiers</td>\n",
       "      <td>0</td>\n",
       "      <td>node_rwwVbaGFJtCHoKTZ6B83Ax</td>\n",
       "      <td>Thiers_1</td>\n",
       "      <td>4744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>Clermont</td>\n",
       "      <td>Ornon</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>link_1ck6aSDmpEy7Jo2fbhNAxE</th>\n",
       "      <td>LINESTRING (3.38307 45.84869, 3.38445 45.8486,...</td>\n",
       "      <td>node_4b2VnuC1zTsPzd9ueovVuH</td>\n",
       "      <td>14.0</td>\n",
       "      <td>600</td>\n",
       "      <td>Thiers</td>\n",
       "      <td>Thiers</td>\n",
       "      <td>0</td>\n",
       "      <td>node_a3ZLvXzFnMqGNGu4hjEYT6</td>\n",
       "      <td>Thiers_1</td>\n",
       "      <td>2344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>Ornon</td>\n",
       "      <td>Thiers</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>link_2sfH8EPaWDjhzsZiZJMz1d</th>\n",
       "      <td>LINESTRING (3.10296 45.78059, 3.10359 45.78092...</td>\n",
       "      <td>node_b8e2FB6qm9PUQTLvQvNucR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7200</td>\n",
       "      <td>ChatelGuyon</td>\n",
       "      <td>ChatelGuyon</td>\n",
       "      <td>0</td>\n",
       "      <td>node_wbHMs2n7zPVS1pp1cXnNw5</td>\n",
       "      <td>ChatelGuyon_1</td>\n",
       "      <td>2980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Clermont</td>\n",
       "      <td>Riom</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>link_oCfgaw42pToYChhHThwCwy</th>\n",
       "      <td>LINESTRING (3.07285 45.8958, 3.07269 45.89586,...</td>\n",
       "      <td>node_f8Fb3oREhTRCmTVNW7TQzE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7200</td>\n",
       "      <td>ChatelGuyon</td>\n",
       "      <td>ChatelGuyon</td>\n",
       "      <td>0</td>\n",
       "      <td>node_b8e2FB6qm9PUQTLvQvNucR</td>\n",
       "      <td>ChatelGuyon_1</td>\n",
       "      <td>1175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Riom</td>\n",
       "      <td>Chatel Guyon</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>link_dy68NZEgkJFiakszXTBmBp</th>\n",
       "      <td>LINESTRING (3.41873 46.12042, 3.41844 46.12023...</td>\n",
       "      <td>node_2zTroDrJuDCKmipdvjBrtL</td>\n",
       "      <td>4.0</td>\n",
       "      <td>700</td>\n",
       "      <td>Gannat</td>\n",
       "      <td>Gannat</td>\n",
       "      <td>0</td>\n",
       "      <td>node_6CErzt5T6gFonN6RkpvAM6</td>\n",
       "      <td>Gannat_1</td>\n",
       "      <td>3295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.2</td>\n",
       "      <td>5.142857</td>\n",
       "      <td>Vichy</td>\n",
       "      <td>Gannat</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      geometry  \\\n",
       "index                                                                            \n",
       "link_qTNjaUDLm9x3yJrS9ubX9T  LINESTRING (3.2042 46.0974, 3.20418 46.09764, ...   \n",
       "link_wvPcELKEW52njEnuK7AeSe  LINESTRING (3.06 45.92018, 3.0606 45.92013, 3....   \n",
       "link_vTbX3V9qJJxThakJ1WZbbk  LINESTRING (3.07285 45.8958, 3.07269 45.89586,...   \n",
       "link_8EachMgBpjP7T2bWPiAc3E  LINESTRING (3.50444 45.85987, 3.50422 45.85993...   \n",
       "link_purLhqauca5SLLCFkShEC7  LINESTRING (3.38307 45.84869, 3.38239 45.84873...   \n",
       "link_4hsYkThjafc1NVpc8kLeid  LINESTRING (3.0996 45.77888, 3.0994 45.77877, ...   \n",
       "link_1ck6aSDmpEy7Jo2fbhNAxE  LINESTRING (3.38307 45.84869, 3.38445 45.8486,...   \n",
       "link_2sfH8EPaWDjhzsZiZJMz1d  LINESTRING (3.10296 45.78059, 3.10359 45.78092...   \n",
       "link_oCfgaw42pToYChhHThwCwy  LINESTRING (3.07285 45.8958, 3.07269 45.89586,...   \n",
       "link_dy68NZEgkJFiakszXTBmBp  LINESTRING (3.41873 46.12042, 3.41844 46.12023...   \n",
       "\n",
       "                                                       b  nb_peak_hours  \\\n",
       "index                                                                     \n",
       "link_qTNjaUDLm9x3yJrS9ubX9T  node_6CErzt5T6gFonN6RkpvAM6            4.0   \n",
       "link_wvPcELKEW52njEnuK7AeSe  node_b8e2FB6qm9PUQTLvQvNucR            NaN   \n",
       "link_vTbX3V9qJJxThakJ1WZbbk  node_wbHMs2n7zPVS1pp1cXnNw5            NaN   \n",
       "link_8EachMgBpjP7T2bWPiAc3E  node_a3ZLvXzFnMqGNGu4hjEYT6           14.0   \n",
       "link_purLhqauca5SLLCFkShEC7  node_rwwVbaGFJtCHoKTZ6B83Ax           14.0   \n",
       "link_4hsYkThjafc1NVpc8kLeid  node_a3ZLvXzFnMqGNGu4hjEYT6           14.0   \n",
       "link_1ck6aSDmpEy7Jo2fbhNAxE  node_4b2VnuC1zTsPzd9ueovVuH           14.0   \n",
       "link_2sfH8EPaWDjhzsZiZJMz1d  node_b8e2FB6qm9PUQTLvQvNucR            NaN   \n",
       "link_oCfgaw42pToYChhHThwCwy  node_f8Fb3oREhTRCmTVNW7TQzE            NaN   \n",
       "link_dy68NZEgkJFiakszXTBmBp  node_2zTroDrJuDCKmipdvjBrtL            4.0   \n",
       "\n",
       "                             headway_oph     route_id route_short_name  \\\n",
       "index                                                                    \n",
       "link_qTNjaUDLm9x3yJrS9ubX9T          700       Gannat           Gannat   \n",
       "link_wvPcELKEW52njEnuK7AeSe         7200  ChatelGuyon      ChatelGuyon   \n",
       "link_vTbX3V9qJJxThakJ1WZbbk         7200  ChatelGuyon      ChatelGuyon   \n",
       "link_8EachMgBpjP7T2bWPiAc3E          600       Thiers           Thiers   \n",
       "link_purLhqauca5SLLCFkShEC7          600       Thiers           Thiers   \n",
       "link_4hsYkThjafc1NVpc8kLeid          600       Thiers           Thiers   \n",
       "link_1ck6aSDmpEy7Jo2fbhNAxE          600       Thiers           Thiers   \n",
       "link_2sfH8EPaWDjhzsZiZJMz1d         7200  ChatelGuyon      ChatelGuyon   \n",
       "link_oCfgaw42pToYChhHThwCwy         7200  ChatelGuyon      ChatelGuyon   \n",
       "link_dy68NZEgkJFiakszXTBmBp          700       Gannat           Gannat   \n",
       "\n",
       "                             pickup_type                            a  \\\n",
       "index                                                                   \n",
       "link_qTNjaUDLm9x3yJrS9ubX9T            0  node_2zTroDrJuDCKmipdvjBrtL   \n",
       "link_wvPcELKEW52njEnuK7AeSe            0  node_f8Fb3oREhTRCmTVNW7TQzE   \n",
       "link_vTbX3V9qJJxThakJ1WZbbk            0  node_b8e2FB6qm9PUQTLvQvNucR   \n",
       "link_8EachMgBpjP7T2bWPiAc3E            0  node_4b2VnuC1zTsPzd9ueovVuH   \n",
       "link_purLhqauca5SLLCFkShEC7            0  node_a3ZLvXzFnMqGNGu4hjEYT6   \n",
       "link_4hsYkThjafc1NVpc8kLeid            0  node_rwwVbaGFJtCHoKTZ6B83Ax   \n",
       "link_1ck6aSDmpEy7Jo2fbhNAxE            0  node_a3ZLvXzFnMqGNGu4hjEYT6   \n",
       "link_2sfH8EPaWDjhzsZiZJMz1d            0  node_wbHMs2n7zPVS1pp1cXnNw5   \n",
       "link_oCfgaw42pToYChhHThwCwy            0  node_b8e2FB6qm9PUQTLvQvNucR   \n",
       "link_dy68NZEgkJFiakszXTBmBp            0  node_6CErzt5T6gFonN6RkpvAM6   \n",
       "\n",
       "                                   trip_id  time  ...  capex  \\\n",
       "index                                             ...          \n",
       "link_qTNjaUDLm9x3yJrS9ubX9T       Gannat_0  3295  ...    0.3   \n",
       "link_wvPcELKEW52njEnuK7AeSe  ChatelGuyon_0  1175  ...    0.3   \n",
       "link_vTbX3V9qJJxThakJ1WZbbk  ChatelGuyon_0  2980  ...    0.3   \n",
       "link_8EachMgBpjP7T2bWPiAc3E       Thiers_0  2344  ...    0.3   \n",
       "link_purLhqauca5SLLCFkShEC7       Thiers_0  4744  ...    0.3   \n",
       "link_4hsYkThjafc1NVpc8kLeid       Thiers_1  4744  ...    0.3   \n",
       "link_1ck6aSDmpEy7Jo2fbhNAxE       Thiers_1  2344  ...    0.3   \n",
       "link_2sfH8EPaWDjhzsZiZJMz1d  ChatelGuyon_1  2980  ...    0.3   \n",
       "link_oCfgaw42pToYChhHThwCwy  ChatelGuyon_1  1175  ...    0.3   \n",
       "link_dy68NZEgkJFiakszXTBmBp       Gannat_1  3295  ...    0.3   \n",
       "\n",
       "                             catchment_radius  line_has_timetable  \\\n",
       "index                                                               \n",
       "link_qTNjaUDLm9x3yJrS9ubX9T               500                   0   \n",
       "link_wvPcELKEW52njEnuK7AeSe               500                   1   \n",
       "link_vTbX3V9qJJxThakJ1WZbbk               500                   1   \n",
       "link_8EachMgBpjP7T2bWPiAc3E               500                   0   \n",
       "link_purLhqauca5SLLCFkShEC7               500                   0   \n",
       "link_4hsYkThjafc1NVpc8kLeid               500                   0   \n",
       "link_1ck6aSDmpEy7Jo2fbhNAxE               500                   0   \n",
       "link_2sfH8EPaWDjhzsZiZJMz1d               500                   1   \n",
       "link_oCfgaw42pToYChhHThwCwy               500                   1   \n",
       "link_dy68NZEgkJFiakszXTBmBp               500                   0   \n",
       "\n",
       "                             frequency_per_day  frequency (veh/hour)  \\\n",
       "index                                                                  \n",
       "link_qTNjaUDLm9x3yJrS9ubX9T               81.0                   NaN   \n",
       "link_wvPcELKEW52njEnuK7AeSe                5.0                   0.5   \n",
       "link_vTbX3V9qJJxThakJ1WZbbk                5.0                   0.5   \n",
       "link_8EachMgBpjP7T2bWPiAc3E               84.0                   6.0   \n",
       "link_purLhqauca5SLLCFkShEC7               84.0                   6.0   \n",
       "link_4hsYkThjafc1NVpc8kLeid               84.0                   6.0   \n",
       "link_1ck6aSDmpEy7Jo2fbhNAxE               84.0                   6.0   \n",
       "link_2sfH8EPaWDjhzsZiZJMz1d                6.0                   0.5   \n",
       "link_oCfgaw42pToYChhHThwCwy                6.0                   0.5   \n",
       "link_dy68NZEgkJFiakszXTBmBp               81.0                   NaN   \n",
       "\n",
       "                             frequency ph (veh/hour) frequency oph (veh/hour)  \\\n",
       "index                                                                           \n",
       "link_qTNjaUDLm9x3yJrS9ubX9T                      7.2                 5.142857   \n",
       "link_wvPcELKEW52njEnuK7AeSe                      0.5                 0.500000   \n",
       "link_vTbX3V9qJJxThakJ1WZbbk                      0.5                 0.500000   \n",
       "link_8EachMgBpjP7T2bWPiAc3E                      6.0                 6.000000   \n",
       "link_purLhqauca5SLLCFkShEC7                      6.0                 6.000000   \n",
       "link_4hsYkThjafc1NVpc8kLeid                      6.0                 6.000000   \n",
       "link_1ck6aSDmpEy7Jo2fbhNAxE                      6.0                 6.000000   \n",
       "link_2sfH8EPaWDjhzsZiZJMz1d                      0.5                 0.500000   \n",
       "link_oCfgaw42pToYChhHThwCwy                      0.5                 0.500000   \n",
       "link_dy68NZEgkJFiakszXTBmBp                      7.2                 5.142857   \n",
       "\n",
       "                                   a_name        b_name  fleet  \n",
       "index                                                           \n",
       "link_qTNjaUDLm9x3yJrS9ubX9T        Gannat         Vichy   12.0  \n",
       "link_wvPcELKEW52njEnuK7AeSe  Chatel Guyon          Riom    3.0  \n",
       "link_vTbX3V9qJJxThakJ1WZbbk          Riom      Clermont    3.0  \n",
       "link_8EachMgBpjP7T2bWPiAc3E        Thiers         Ornon   24.0  \n",
       "link_purLhqauca5SLLCFkShEC7         Ornon      Clermont   24.0  \n",
       "link_4hsYkThjafc1NVpc8kLeid      Clermont         Ornon   24.0  \n",
       "link_1ck6aSDmpEy7Jo2fbhNAxE         Ornon        Thiers   24.0  \n",
       "link_2sfH8EPaWDjhzsZiZJMz1d      Clermont          Riom    3.0  \n",
       "link_oCfgaw42pToYChhHThwCwy          Riom  Chatel Guyon    3.0  \n",
       "link_dy68NZEgkJFiakszXTBmBp         Vichy        Gannat   12.0  \n",
       "\n",
       "[10 rows x 38 columns]"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f98a64c",
   "metadata": {},
   "source": [
    "# Vehicle revenue KM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "c70257d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequency = freq moy jour\n",
    "def get_veh_kmh(col='route_id', length_col='length'):\n",
    "    link = links.groupby([col, 'trip_id'])[[length_col, 'frequency_per_day', 'nb_service_hours']].agg({length_col:'sum', 'frequency_per_day': 'mean', 'nb_service_hours': 'mean'})\n",
    "    link['veh_km/h'] = np.ceil(link['frequency_per_day'] * link[length_col]) / 1000 / link['nb_service_hours'] #to km/H\n",
    "    return link.reset_index().groupby(col)['veh_km/h'].agg('sum').to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "cd7fef27",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_veh_kmh('route_id', 'length')\n",
    "df_route_id['veh_km/h'] = res\n",
    "df_route_id['capex'] = df_route_id['veh_km/h'] * default_capex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "da1348cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = df_route_id.reset_index().groupby('route_type')['capex'].sum()\n",
    "df_route_type['capex'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25927ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO : multiplier par l'amplitude horaire pour avoir une valeur journalière\n",
    "#TODO : multiplier par capex pour avoir les coûts d'exploitation afférents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab77743f",
   "metadata": {},
   "source": [
    "# Round trip time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "fd818c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_round_trip_time(col='route_id'):\n",
    "    link = links.groupby([col,'trip_id'])[['time']].agg('sum')\n",
    "    return link.reset_index().groupby(col)['time'].agg('sum').to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869ea67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_round_trip_time('route_id')\n",
    "\n",
    "df_route_id['round trip time (s)'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "8a459f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_type</th>\n",
       "      <th>veh_capacity (PAX)</th>\n",
       "      <th>headway</th>\n",
       "      <th>headway_ph</th>\n",
       "      <th>headway_oph</th>\n",
       "      <th>nb_peak_hours</th>\n",
       "      <th>catchment population</th>\n",
       "      <th>frequency (veh/day)</th>\n",
       "      <th>frequency (veh/hour)</th>\n",
       "      <th>frequency ph (veh/hour)</th>\n",
       "      <th>...</th>\n",
       "      <th>stations sequence</th>\n",
       "      <th>nodes sequence</th>\n",
       "      <th>nb stations</th>\n",
       "      <th>connexions</th>\n",
       "      <th>nb lines connected</th>\n",
       "      <th>fleet</th>\n",
       "      <th>nb_service_hours</th>\n",
       "      <th>veh_km/h</th>\n",
       "      <th>capex</th>\n",
       "      <th>round trip time (s)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>route_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gannat</th>\n",
       "      <td>bus</td>\n",
       "      <td>60</td>\n",
       "      <td>600</td>\n",
       "      <td>500</td>\n",
       "      <td>800</td>\n",
       "      <td>4</td>\n",
       "      <td>1078.244331</td>\n",
       "      <td>81.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25920.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[Gannat, Vichy]</td>\n",
       "      <td>[node_2zTroDrJuDCKmipdvjBrtL, node_6CErzt5T6gF...</td>\n",
       "      <td>2</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>211.815000</td>\n",
       "      <td>63.544500</td>\n",
       "      <td>6590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChatelGuyon</th>\n",
       "      <td>bus</td>\n",
       "      <td>60</td>\n",
       "      <td>600</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1610.494104</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[Chatel Guyon, Riom, Clermont]</td>\n",
       "      <td>[node_f8Fb3oREhTRCmTVNW7TQzE, node_b8e2FB6qm9P...</td>\n",
       "      <td>3</td>\n",
       "      <td>{'bus': ['Thiers']}</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.157583</td>\n",
       "      <td>6.347275</td>\n",
       "      <td>8310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thiers</th>\n",
       "      <td>bus</td>\n",
       "      <td>60</td>\n",
       "      <td>600</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2002.746734</td>\n",
       "      <td>84.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[Thiers, Ornon, Clermont]</td>\n",
       "      <td>[node_4b2VnuC1zTsPzd9ueovVuH, node_a3ZLvXzFnMq...</td>\n",
       "      <td>3</td>\n",
       "      <td>{'bus': ['ChatelGuyon']}</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>472.488000</td>\n",
       "      <td>141.746400</td>\n",
       "      <td>14176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            route_type  veh_capacity (PAX)  headway headway_ph headway_oph  \\\n",
       "route_id                                                                     \n",
       "Gannat             bus                  60      600        500         800   \n",
       "ChatelGuyon        bus                  60      600       None        None   \n",
       "Thiers             bus                  60      600       None        None   \n",
       "\n",
       "            nb_peak_hours  catchment population  frequency (veh/day)  \\\n",
       "route_id                                                               \n",
       "Gannat                  4           1078.244331                 81.0   \n",
       "ChatelGuyon          None           1610.494104                  5.5   \n",
       "Thiers               None           2002.746734                 84.0   \n",
       "\n",
       "             frequency (veh/hour)  frequency ph (veh/hour)  ...  \\\n",
       "route_id                                                    ...   \n",
       "Gannat                        NaN                  25920.0  ...   \n",
       "ChatelGuyon                   0.5                      NaN  ...   \n",
       "Thiers                        6.0                      NaN  ...   \n",
       "\n",
       "                          stations sequence  \\\n",
       "route_id                                      \n",
       "Gannat                      [Gannat, Vichy]   \n",
       "ChatelGuyon  [Chatel Guyon, Riom, Clermont]   \n",
       "Thiers            [Thiers, Ornon, Clermont]   \n",
       "\n",
       "                                                nodes sequence nb stations  \\\n",
       "route_id                                                                     \n",
       "Gannat       [node_2zTroDrJuDCKmipdvjBrtL, node_6CErzt5T6gF...           2   \n",
       "ChatelGuyon  [node_f8Fb3oREhTRCmTVNW7TQzE, node_b8e2FB6qm9P...           3   \n",
       "Thiers       [node_4b2VnuC1zTsPzd9ueovVuH, node_a3ZLvXzFnMq...           3   \n",
       "\n",
       "                           connexions nb lines connected  fleet  \\\n",
       "route_id                                                          \n",
       "Gannat                             {}                  0   12.0   \n",
       "ChatelGuyon       {'bus': ['Thiers']}                  1    3.0   \n",
       "Thiers       {'bus': ['ChatelGuyon']}                  1   24.0   \n",
       "\n",
       "            nb_service_hours    veh_km/h       capex  round trip time (s)  \n",
       "route_id                                                                   \n",
       "Gannat                  14.0  211.815000   63.544500                 6590  \n",
       "ChatelGuyon             12.0   21.157583    6.347275                 8310  \n",
       "Thiers                  14.0  472.488000  141.746400                14176  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_route_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5213bf",
   "metadata": {},
   "source": [
    "# Export results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7948cbd",
   "metadata": {},
   "source": [
    "## Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "37b8d896",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO : formater les tableaux de sortie de df_route_id ==> caractéristiques / accessibilité / réponse au besoin\n",
    "# Dans caractéristiques : longueur (km), temps de parcours (min), vitesse moyenne (km/h), nombre d'arrêts, fréquence attendue (nb services / sens / jour), flotte, vehicle capacity, veh.km/jour, capex/jour, veh.km/an, capex/an\n",
    "# Dans accessibilité : toutes les valeurs de catchment par item et mode d'accès\n",
    "# Dans réponse au besoin : estimation du volume de flux TC desservis sans correspondance pour une PM de 20%, estimation du taux de remplissage TC sans correspondance pour une PM TC de 10%\n",
    "\n",
    "#TODO: ajouter les tableaux globaux df_route_type (longueur totale, nombre de stations, flotte, veh.km/jour, capex/jour, veh.km/an, capex/an) et hubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4a7d0d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# round numbers\n",
    "#TODO : change label catchment\n",
    "# for col in ['catchment population', 'frequency (veh/hours)','length (m)','veh.km/h','round trip time (s)']:\n",
    "#     df_route_id[col] = df_route_id[col].apply(lambda x :np.round(x,2))\n",
    "#     df_route_id[col] = df_route_id[col].apply(lambda x :np.round(x,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3105f92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_route_id = df_route_id.fillna('null')\n",
    "#df_route_type = df_route_type.fillna('null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "984694c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_route_id.to_csv(output_folder + 'route_id_metrics.csv')\n",
    "# df_route_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c6a5c283",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_route_type.to_csv(output_folder + 'route_type_metrics.csv')\n",
    "# df_route_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1a948d",
   "metadata": {},
   "source": [
    "## Geomatic outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dcea6b",
   "metadata": {},
   "source": [
    "Hubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "395318b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hubs_plot = hubs.copy()\n",
    "hubs_plot['lines'] = hubs_plot['lines'].apply(lambda x: str(x).replace(',', ';').replace(\"'\", '')[1:-1])\n",
    "hubs_plot.to_csv(output_folder + 'hubs.csv')\n",
    "\n",
    "hubs = gpd.GeoDataFrame(hubs, geometry='geometry', crs='EPSG:4326')\n",
    "hubs.to_file(output_folder + 'hubs.geojson', driver='GeoJSON', engine=io_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b22e89",
   "metadata": {},
   "source": [
    "Common sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2cf546b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renvoie un fichier geojson avec les tronçons en commun entre plusieurs lignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8ad927d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering de 500m pour a et b et cluster d'appartenance\n",
    "coords_nodes = np.array(nodes['geometry'].apply(lambda point: (point.x, point.y)).tolist())\n",
    "\n",
    "# Convertir 500 mètres en degrés : 111 km = 1 degré de latitude\n",
    "eps_lat = clustering_radius / (111 * 1000)  # Environ 0.0045 degrés\n",
    "\n",
    "# 1 degré de longitude dépend de la latitude\n",
    "mean_latitude = np.mean(coords_nodes[:, 1])\n",
    "eps_lon = clustering_radius / (111 * 1000 * np.cos(np.radians(mean_latitude)))\n",
    "\n",
    "# Appliquer DBSCAN avec une distance euclidienne pondérée\n",
    "db = DBSCAN(eps=1, min_samples=1, metric='euclidean').fit(coords_nodes / [eps_lon, eps_lat])\n",
    "\n",
    "# Ajouter les labels de cluster au GeoDataFrame\n",
    "nodes['cluster'] = db.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "de33553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = nodes.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "605b754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = links.merge(nodes[['index', 'cluster']], left_on='a', right_on='index', how='left').drop(columns='index').rename(columns={'cluster': 'a_clustered'})\n",
    "links = links.merge(nodes[['index', 'cluster']], left_on='b', right_on='index', how='left').drop(columns='index').rename(columns={'cluster': 'b_clustered'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "43462dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_troncons = links.groupby(['a_clustered', 'b_clustered'])['route_id'].agg(list).reset_index()\n",
    "l_troncons['nb_lines'] = l_troncons['route_id'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7a122690",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_troncons_communs = l_troncons[l_troncons.nb_lines > 1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "77eaadb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_troncons_communs['geometry'] = l_troncons_communs.apply(\n",
    "    lambda row : links[(links.a_clustered == row['a_clustered']) & (links.b_clustered == row['b_clustered'])].drop_duplicates(subset=['a_clustered', 'b_clustered'], keep='first').geometry.values[0],\n",
    "    axis=1\n",
    "    )\n",
    "l_troncons_communs['stations_a'] = l_troncons_communs['a_clustered'].apply(lambda x: list(nodes[nodes.cluster == x]['stop_name'].unique()))\n",
    "l_troncons_communs['stations_b'] = l_troncons_communs['b_clustered'].apply(lambda x: list(nodes[nodes.cluster == x]['stop_name'].unique()))\n",
    "l_troncons_communs = gpd.GeoDataFrame(l_troncons_communs[['stations_a', 'stations_b', 'route_id', 'nb_lines', 'geometry']], geometry='geometry', crs='EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "62cc07fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_troncons_communs.to_file(output_folder + 'pt_common_sections.geojson', driver='GeoJSON', engine=io_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6559846b",
   "metadata": {},
   "source": [
    "Nodes catchment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "01bc6f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO pcq c'est visuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "10166c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using get catchment : get the catchment radius of each node (get larger one if used by many modes)\n",
    "# link = links.groupby('route_type')[['a', 'b', 'route_type']].agg({'a': set, 'b': set, 'route_type': 'first'})\n",
    "# link['node'] = link.apply(lambda row: row['a'].union(row['b']), axis=1)\n",
    "# link = link.drop(columns=['a','b'])\n",
    "# # add catchment radius for the route_type\n",
    "# link['catchment_radius'] = link['route_type'].apply(lambda x: catchment_radius.get(x,default_catchment_radius))\n",
    "# link = link.explode('node').reset_index(drop=True)\n",
    "# link = link.sort_values('catchment_radius',ascending=False).drop_duplicates('node',keep='first')\n",
    "# link = node_dist.merge(link, left_on='node_index', right_on='node')\n",
    "# link = link[link['distances'] <= link['catchment_radius']]\n",
    "\n",
    "# temp_dict = link.groupby('node_index')['population'].sum().to_dict()\n",
    "# nodes['catchment'] = nodes.index.map(temp_dict.get)\n",
    "\n",
    "# temp_dict = link.groupby('node_index')['catchment_radius'].agg('first').to_dict() \n",
    "# nodes['catchment_radius'] = nodes.index.map(temp_dict.get)\n",
    "\n",
    "# nodes.to_file(output_folder + 'nodes.geojson', driver='GeoJSON', engine=io_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204675d1",
   "metadata": {},
   "source": [
    "## Graphs and pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ba0c4f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot = df_route_type.reset_index().plot(kind='bar', x='route_type', y='catchment', color='#559bb4', rot=0, figsize=[10, 5])\n",
    "# plot.set_title('Couverture population par mode')\n",
    "# plot.set_ylabel('')\n",
    "# plot.set_xlabel(\"route_type\")\n",
    "# plot.legend([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767a079a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
